# ‚úÖ Performance, Tuning & Scaling

---

## üî∏ Kafka Performance Tuning

### Producer Performance:
- **`batch.size`**: Larger batches = higher throughput (try 64KB-256KB)
- **`linger.ms`**: Wait time to fill batches (5-20ms for balance)
- **`compression.type`**: Use `snappy` or `zstd` for CPU/network trade-off
- **`buffer.memory`**: Total producer memory (increase for high-throughput)
- **`acks=1`**: Balance between durability and speed

### Consumer Performance:
- **`fetch.min.bytes`**: Wait for larger batches from broker (32KB-1MB)
- **`fetch.max.wait.ms`**: Max wait time for fetch (reduce for low latency)
- **`max.poll.records`**: Records per poll (increase for throughput)
- **Multiple consumers**: Scale horizontally up to partition count

### Interview Points:
- *"Producer spends most time waiting for batches to fill"* ‚Üí tune `linger.ms`
- *"Consumer lag increasing"* ‚Üí increase `fetch.min.bytes` and `max.poll.records`
- *"High CPU usage"* ‚Üí reduce compression or increase batch sizes
- **Rule of thumb**: Start with defaults, measure, then tune based on bottlenecks

---

## üî∏ Kafka Storage Internals

### Log Structure:
- **Segments**: Partition split into 1GB files (configurable)
- **Active segment**: Currently being written to
- **Closed segments**: Immutable, eligible for cleanup

### Retention Policies:
```properties
# Time-based (default 7 days)
log.retention.hours=168

# Size-based 
log.retention.bytes=1073741824

# Cleanup policies
log.cleanup.policy=delete  # or compact
```

### Log Compaction:
- Keeps **latest value per key** only
- Useful for **changelog/state streams**
- **Tombstone records** (null value) delete keys
- Background process, not real-time

### Indexes:
- **Offset index**: Maps offset ‚Üí file position
- **Timestamp index**: Maps timestamp ‚Üí offset
- Enables fast seeking without scanning entire log

### Interview Points:
- *"When to use compaction vs deletion?"* ‚Üí Compaction for state/config topics, deletion for events
- *"How does Kafka achieve fast reads?"* ‚Üí Indexes + sequential I/O + OS page cache
- *"What happens when disk is full?"* ‚Üí Kafka stops accepting writes, retention cleanup kicks in

---

## üî∏ High Availability & Fault Tolerance

### Replication:
- **Replication factor**: Number of replicas (typically 3)
- **Leader**: Handles all reads/writes for partition
- **Followers**: Replicate leader's data
- **ISR**: In-sync replicas that can become leader

### Leader Election:
- Automatic when leader fails
- New leader chosen from ISR
- **Unclean leader election**: Allow out-of-sync replica to become leader (data loss risk)

### Configuration for HA:
```properties
# Replication
default.replication.factor=3
min.insync.replicas=2

# Leader election
unclean.leader.election.enable=false  # Prefer consistency over availability
```

### Durability Guarantees:
- **Producer**: `acks=all` waits for all ISR replicas
- **Broker**: Configurable flush intervals
- **Storage**: Data persisted to disk with fsync

### Interview Points:
- *"What if entire rack fails?"* ‚Üí Use rack-aware replica placement
- *"Trade-off between availability and consistency?"* ‚Üí min.insync.replicas vs unclean election
- *"How long does failover take?"* ‚Üí Typically 30 seconds (controlled by session timeouts)

---

## üî∏ Kafka in Production: Monitoring & Metrics

### Critical JMX Metrics:

**Broker Metrics:**
- `kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec`
- `kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec`
- `kafka.log:type=LogSize,name=Size` (disk usage)
- `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions`

**Consumer Metrics:**
- `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,attribute=lag-sum`
- `kafka.consumer:type=consumer-coordinator-metrics,client-id=*,attribute=commit-rate`

**Producer Metrics:**
- `kafka.producer:type=producer-metrics,client-id=*,attribute=record-send-rate`
- `kafka.producer:type=producer-metrics,client-id=*,attribute=batch-size-avg`

### Monitoring Tools:
- **JMX + Prometheus**: Export metrics for alerting
- **Kafka Manager/AKHQ**: Web UI for cluster management
- **Confluent Control Center**: Commercial monitoring solution
- **Burrow**: LinkedIn's consumer lag monitoring

### Key Alerts:
- Consumer lag > threshold
- Under-replicated partitions > 0
- Disk usage > 80%
- ISR shrinking events

### Interview Points:
- *"Most important metric to monitor?"* ‚Üí Consumer lag (indicates processing health)
- *"How to detect broker issues?"* ‚Üí Under-replicated partitions, high request latency
- *"Capacity planning metrics?"* ‚Üí Disk usage, network I/O, CPU utilization

---

## üî∏ Backpressure and Consumer Lag

### Consumer Lag Types:
- **Time lag**: How far behind in time
- **Offset lag**: Number of unprocessed messages
- **Partition lag**: Per-partition offset difference

### Identifying Lag Causes:
1. **Slow consumer processing**: Optimize business logic
2. **Under-provisioned consumers**: Scale horizontally
3. **Producer burst**: Temporary spike in incoming data
4. **Network issues**: Check connectivity and bandwidth
5. **Rebalancing**: Frequent group membership changes

### Mitigation Strategies:

**Scaling Solutions:**
```java
// Add more consumers (up to partition count)
// Increase processing batch size
consumer.poll(Duration.ofMillis(100)); // Longer poll timeout
```

**Rate Limiting:**
```java
// Pause consumption when downstream is slow
if (isDownstreamSlow()) {
    consumer.pause(consumer.assignment());
} else {
    consumer.resume(consumer.assignment());
}
```

**Processing Optimization:**
- Async processing with worker threads
- Batch database operations
- Cache frequently accessed data
- Use connection pooling

### Advanced Techniques:
- **Priority queues**: Process high-priority messages first
- **Circuit breakers**: Fail fast when downstream is unavailable
- **Backoff strategies**: Exponential backoff for retries

### Interview Points:
- *"Consumer lag is increasing during peak hours. What do you check?"* ‚Üí Processing time per message, consumer group size, partition distribution
- *"How to handle temporary traffic spikes?"* ‚Üí Auto-scaling consumers, buffering, or graceful degradation
- *"When to pause vs scale consumers?"* ‚Üí Pause for downstream issues, scale for sustained high load

---

## üî∏ Quick Reference Table

| Topic            | Key Concepts                               | Main Tuning Parameters                      |
|------------------|--------------------------------------------|---------------------------------------------|
| **Performance**  | Batching, compression, parallelism         | batch.size, linger.ms, fetch.min.bytes      |
| **Storage**      | Segments, retention, compaction            | log.retention.hours, log.cleanup.policy     |
| **HA/FT**        | Replication, leader election, ISR          | replication.factor, min.insync.replicas     |
| **Monitoring**   | JMX metrics, consumer lag, alerts          | MessagesInPerSec, UnderReplicatedPartitions |
| **Backpressure** | Lag identification, scaling, rate limiting | Consumer scaling, pause/resume              |

---

## ‚ùì Quick Interview Questions

**Performance:** "How would you tune Kafka for maximum throughput vs minimum latency?"

**Storage:** "Explain when you'd use log compaction vs time-based retention."

**HA/FT:** "What's the trade-off between availability and consistency in Kafka?"

**Monitoring:** "What metrics would you alert on in production Kafka?"

**Backpressure:** "Consumer lag is growing. Walk me through your debugging process."