{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SWE Notes Welcome to my Software Engineering notebook! Here you'll find concise deep-dives into common algorithms, data structures, and C++ essentials\u2014all in Markdown. What's Inside Algorithms : Backtracking \u00b7 Greedy \u00b7 Dynamic Programming \u00b7 Graphs and more C++ : STL and language idioms Data Structures : Common implementations and usage patterns Why This Notebook? I created this collection to: - Serve as a personal reference for technical interviews - Document elegant solutions to common problems - Share knowledge with fellow software engineers Feel free to explore the sections and contribute if you find it useful! Getting Started Check out these popular sections: Dynamic Programming Data Structures C++ STL","title":"Home"},{"location":"#swe-notes","text":"Welcome to my Software Engineering notebook! Here you'll find concise deep-dives into common algorithms, data structures, and C++ essentials\u2014all in Markdown.","title":"SWE Notes"},{"location":"#whats-inside","text":"Algorithms : Backtracking \u00b7 Greedy \u00b7 Dynamic Programming \u00b7 Graphs and more C++ : STL and language idioms Data Structures : Common implementations and usage patterns","title":"What's Inside"},{"location":"#why-this-notebook","text":"I created this collection to: - Serve as a personal reference for technical interviews - Document elegant solutions to common problems - Share knowledge with fellow software engineers Feel free to explore the sections and contribute if you find it useful!","title":"Why This Notebook?"},{"location":"#getting-started","text":"Check out these popular sections: Dynamic Programming Data Structures C++ STL","title":"Getting Started"},{"location":"navigation/","text":"Navigation Home Algorithms Backtracking Data Structures Dynamic Programming Graphs Greedy Math Searching Sorting Strings C++ STL System Design Ad Click Aggregator Dropbox Live Comments Ticketmaster Tinder Uber Whatsapp YouTube YouTube Top K","title":"Navigation"},{"location":"navigation/#navigation","text":"Home Algorithms Backtracking Data Structures Dynamic Programming Graphs Greedy Math Searching Sorting Strings C++ STL System Design Ad Click Aggregator Dropbox Live Comments Ticketmaster Tinder Uber Whatsapp YouTube YouTube Top K","title":"Navigation"},{"location":"algorithms/backtracking/","text":"Backtracking Algorithms Backtracking is an algorithmic technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, and removing those solutions that fail to satisfy the constraints of the problem. Core Concept The backtracking algorithm traverses the search tree recursively, from the root down. As it traverses, it: Chooses one option from the available choices Explores that option recursively If that option leads to a solution, great! If not, backtracks to explore other options Template for Backtracking Problems void backtrack(state, choices) { // Base case: if we've found a solution if (isValidSolution(state)) { storeSolution(state); return; } // Try each available choice for (choice in availableChoices) { // Skip invalid choices early if (!isValid(state, choice)) continue; // Make the choice applyChoice(state, choice); // Recurse backtrack(state, remainingChoices); // Undo the choice (backtrack) undoChoice(state, choice); } } Common Backtracking Problems N-Queens bool isValid(vector<int>& queens, int row, int col) { for (int i = 0; i < row; i++) { // Check vertical and diagonal attacks if (queens[i] == col || abs(queens[i] - col) == abs(i - row)) return false; } return true; } void solveNQueens(int n, int row, vector<int>& queens, vector<vector<string>>& results) { if (row == n) { // Found a valid placement of queens storeSolution(queens, results); return; } for (int col = 0; col < n; col++) { if (isValid(queens, row, col)) { queens[row] = col; solveNQueens(n, row + 1, queens, results); // No explicit backtracking needed, as we overwrite queens[row] } } } Permutations void generatePermutations(vector<int>& nums, int start, vector<vector<int>>& result) { if (start == nums.size()) { result.push_back(nums); return; } for (int i = start; i < nums.size(); i++) { // Swap to create a new permutation swap(nums[start], nums[i]); // Recurse generatePermutations(nums, start + 1, result); // Backtrack - restore the original array swap(nums[start], nums[i]); } } Time Complexity Most backtracking algorithms have exponential time complexity: - N-Queens : O(N!) - Permutations : O(N!) - Combinations : O(2^N) When to Use Backtracking Problems where you need to find all (or some) solutions Constraint satisfaction problems Combinatorial optimization Problems where you need to explore all possibilities","title":"Backtracking"},{"location":"algorithms/backtracking/#backtracking-algorithms","text":"Backtracking is an algorithmic technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, and removing those solutions that fail to satisfy the constraints of the problem.","title":"Backtracking Algorithms"},{"location":"algorithms/backtracking/#core-concept","text":"The backtracking algorithm traverses the search tree recursively, from the root down. As it traverses, it: Chooses one option from the available choices Explores that option recursively If that option leads to a solution, great! If not, backtracks to explore other options","title":"Core Concept"},{"location":"algorithms/backtracking/#template-for-backtracking-problems","text":"void backtrack(state, choices) { // Base case: if we've found a solution if (isValidSolution(state)) { storeSolution(state); return; } // Try each available choice for (choice in availableChoices) { // Skip invalid choices early if (!isValid(state, choice)) continue; // Make the choice applyChoice(state, choice); // Recurse backtrack(state, remainingChoices); // Undo the choice (backtrack) undoChoice(state, choice); } }","title":"Template for Backtracking Problems"},{"location":"algorithms/backtracking/#common-backtracking-problems","text":"","title":"Common Backtracking Problems"},{"location":"algorithms/backtracking/#n-queens","text":"bool isValid(vector<int>& queens, int row, int col) { for (int i = 0; i < row; i++) { // Check vertical and diagonal attacks if (queens[i] == col || abs(queens[i] - col) == abs(i - row)) return false; } return true; } void solveNQueens(int n, int row, vector<int>& queens, vector<vector<string>>& results) { if (row == n) { // Found a valid placement of queens storeSolution(queens, results); return; } for (int col = 0; col < n; col++) { if (isValid(queens, row, col)) { queens[row] = col; solveNQueens(n, row + 1, queens, results); // No explicit backtracking needed, as we overwrite queens[row] } } }","title":"N-Queens"},{"location":"algorithms/backtracking/#permutations","text":"void generatePermutations(vector<int>& nums, int start, vector<vector<int>>& result) { if (start == nums.size()) { result.push_back(nums); return; } for (int i = start; i < nums.size(); i++) { // Swap to create a new permutation swap(nums[start], nums[i]); // Recurse generatePermutations(nums, start + 1, result); // Backtrack - restore the original array swap(nums[start], nums[i]); } }","title":"Permutations"},{"location":"algorithms/backtracking/#time-complexity","text":"Most backtracking algorithms have exponential time complexity: - N-Queens : O(N!) - Permutations : O(N!) - Combinations : O(2^N)","title":"Time Complexity"},{"location":"algorithms/backtracking/#when-to-use-backtracking","text":"Problems where you need to find all (or some) solutions Constraint satisfaction problems Combinatorial optimization Problems where you need to explore all possibilities","title":"When to Use Backtracking"},{"location":"algorithms/data-structures/","text":"Data Structures A comprehensive guide to common data structures with implementation details and time complexity analysis. Arrays Arrays store elements in contiguous memory locations, providing O(1) access by index. // C++ array declaration int staticArray[5] = {1, 2, 3, 4, 5}; // Dynamic array (vector in C++) vector<int> dynamicArray = {1, 2, 3, 4, 5}; Time Complexities: - Access: O(1) - Search: O(n) - Insert/Delete at end: O(1) amortized - Insert/Delete at arbitrary position: O(n) Linked Lists Linked lists store elements in nodes, each pointing to the next node in the sequence. struct ListNode { int val; ListNode *next; ListNode(int x) : val(x), next(nullptr) {} }; Time Complexities: - Access: O(n) - Search: O(n) - Insert/Delete at beginning: O(1) - Insert/Delete at end: O(n) (O(1) with tail pointer) - Insert/Delete at position: O(n) Stacks LIFO (Last In, First Out) data structure. stack<int> s; s.push(1); s.push(2); int top = s.top(); // 2 s.pop(); Time Complexities: - Push: O(1) - Pop: O(1) - Top: O(1) Queues FIFO (First In, First Out) data structure. queue<int> q; q.push(1); q.push(2); int front = q.front(); // 1 q.pop(); Time Complexities: - Push: O(1) - Pop: O(1) - Front: O(1) Hash Tables Hash tables map keys to values using a hash function. unordered_map<string, int> hashMap; hashMap[\"apple\"] = 5; int value = hashMap[\"apple\"]; // 5 Time Complexities: - Insert: O(1) average, O(n) worst - Delete: O(1) average, O(n) worst - Search: O(1) average, O(n) worst Trees Binary Tree struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} }; Binary Search Tree (BST) // BST Property: left->val < node->val < right->val // Search in BST TreeNode* search(TreeNode* root, int key) { if (!root || root->val == key) return root; if (key < root->val) return search(root->left, key); return search(root->right, key); } Time Complexities (Balanced BST): - Search: O(log n) - Insert: O(log n) - Delete: O(log n) Heaps A binary heap is a complete binary tree where each node is either greater than or equal to (max-heap) or less than or equal to (min-heap) its children. // Min-heap in C++ priority_queue<int, vector<int>, greater<int>> minHeap; minHeap.push(3); minHeap.push(1); minHeap.push(2); int min = minHeap.top(); // 1 Time Complexities: - Insert: O(log n) - Extract Min/Max: O(log n) - Peek: O(1) - Heapify: O(n) Graphs Graphs consist of nodes (vertices) and edges connecting them. Representation: Adjacency Matrix: vector<vector<int>> graph(n, vector<int>(n, 0)); // Add edge from u to v graph[u][v] = 1; Adjacency List: vector<vector<int>> graph(n); // Add edge from u to v graph[u].push_back(v); Time Complexities (Adjacency List): - Add Edge: O(1) - Remove Edge: O(E) where E is the number of edges - Check if edge exists: O(E) Trie A tree-like data structure used for storing a dynamic set of strings. struct TrieNode { TrieNode* children[26]; bool isEndOfWord; TrieNode() { isEndOfWord = false; for (int i = 0; i < 26; i++) children[i] = nullptr; } }; Time Complexities: - Insert: O(L) where L is the length of the string - Search: O(L) - Delete: O(L) Union-Find (Disjoint Set) Used to track disjoint sets and perform union operations on them. class DisjointSet { vector<int> parent, rank; public: DisjointSet(int n) { parent.resize(n); rank.resize(n, 0); for (int i = 0; i < n; i++) parent[i] = i; } int find(int x) { if (parent[x] != x) parent[x] = find(parent[x]); return parent[x]; } void unionSets(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX == rootY) return; if (rank[rootX] < rank[rootY]) parent[rootX] = rootY; else if (rank[rootX] > rank[rootY]) parent[rootY] = rootX; else { parent[rootY] = rootX; rank[rootX]++; } } }; Time Complexities (with path compression and union by rank): - Find: O(\u03b1(n)) (effectively O(1)) - Union: O(\u03b1(n)) (effectively O(1))","title":"Data Structures"},{"location":"algorithms/data-structures/#data-structures","text":"A comprehensive guide to common data structures with implementation details and time complexity analysis.","title":"Data Structures"},{"location":"algorithms/data-structures/#arrays","text":"Arrays store elements in contiguous memory locations, providing O(1) access by index. // C++ array declaration int staticArray[5] = {1, 2, 3, 4, 5}; // Dynamic array (vector in C++) vector<int> dynamicArray = {1, 2, 3, 4, 5}; Time Complexities: - Access: O(1) - Search: O(n) - Insert/Delete at end: O(1) amortized - Insert/Delete at arbitrary position: O(n)","title":"Arrays"},{"location":"algorithms/data-structures/#linked-lists","text":"Linked lists store elements in nodes, each pointing to the next node in the sequence. struct ListNode { int val; ListNode *next; ListNode(int x) : val(x), next(nullptr) {} }; Time Complexities: - Access: O(n) - Search: O(n) - Insert/Delete at beginning: O(1) - Insert/Delete at end: O(n) (O(1) with tail pointer) - Insert/Delete at position: O(n)","title":"Linked Lists"},{"location":"algorithms/data-structures/#stacks","text":"LIFO (Last In, First Out) data structure. stack<int> s; s.push(1); s.push(2); int top = s.top(); // 2 s.pop(); Time Complexities: - Push: O(1) - Pop: O(1) - Top: O(1)","title":"Stacks"},{"location":"algorithms/data-structures/#queues","text":"FIFO (First In, First Out) data structure. queue<int> q; q.push(1); q.push(2); int front = q.front(); // 1 q.pop(); Time Complexities: - Push: O(1) - Pop: O(1) - Front: O(1)","title":"Queues"},{"location":"algorithms/data-structures/#hash-tables","text":"Hash tables map keys to values using a hash function. unordered_map<string, int> hashMap; hashMap[\"apple\"] = 5; int value = hashMap[\"apple\"]; // 5 Time Complexities: - Insert: O(1) average, O(n) worst - Delete: O(1) average, O(n) worst - Search: O(1) average, O(n) worst","title":"Hash Tables"},{"location":"algorithms/data-structures/#trees","text":"","title":"Trees"},{"location":"algorithms/data-structures/#binary-tree","text":"struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} };","title":"Binary Tree"},{"location":"algorithms/data-structures/#binary-search-tree-bst","text":"// BST Property: left->val < node->val < right->val // Search in BST TreeNode* search(TreeNode* root, int key) { if (!root || root->val == key) return root; if (key < root->val) return search(root->left, key); return search(root->right, key); } Time Complexities (Balanced BST): - Search: O(log n) - Insert: O(log n) - Delete: O(log n)","title":"Binary Search Tree (BST)"},{"location":"algorithms/data-structures/#heaps","text":"A binary heap is a complete binary tree where each node is either greater than or equal to (max-heap) or less than or equal to (min-heap) its children. // Min-heap in C++ priority_queue<int, vector<int>, greater<int>> minHeap; minHeap.push(3); minHeap.push(1); minHeap.push(2); int min = minHeap.top(); // 1 Time Complexities: - Insert: O(log n) - Extract Min/Max: O(log n) - Peek: O(1) - Heapify: O(n)","title":"Heaps"},{"location":"algorithms/data-structures/#graphs","text":"Graphs consist of nodes (vertices) and edges connecting them. Representation: Adjacency Matrix: vector<vector<int>> graph(n, vector<int>(n, 0)); // Add edge from u to v graph[u][v] = 1; Adjacency List: vector<vector<int>> graph(n); // Add edge from u to v graph[u].push_back(v); Time Complexities (Adjacency List): - Add Edge: O(1) - Remove Edge: O(E) where E is the number of edges - Check if edge exists: O(E)","title":"Graphs"},{"location":"algorithms/data-structures/#trie","text":"A tree-like data structure used for storing a dynamic set of strings. struct TrieNode { TrieNode* children[26]; bool isEndOfWord; TrieNode() { isEndOfWord = false; for (int i = 0; i < 26; i++) children[i] = nullptr; } }; Time Complexities: - Insert: O(L) where L is the length of the string - Search: O(L) - Delete: O(L)","title":"Trie"},{"location":"algorithms/data-structures/#union-find-disjoint-set","text":"Used to track disjoint sets and perform union operations on them. class DisjointSet { vector<int> parent, rank; public: DisjointSet(int n) { parent.resize(n); rank.resize(n, 0); for (int i = 0; i < n; i++) parent[i] = i; } int find(int x) { if (parent[x] != x) parent[x] = find(parent[x]); return parent[x]; } void unionSets(int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX == rootY) return; if (rank[rootX] < rank[rootY]) parent[rootX] = rootY; else if (rank[rootX] > rank[rootY]) parent[rootY] = rootX; else { parent[rootY] = rootX; rank[rootX]++; } } }; Time Complexities (with path compression and union by rank): - Find: O(\u03b1(n)) (effectively O(1)) - Union: O(\u03b1(n)) (effectively O(1))","title":"Union-Find (Disjoint Set)"},{"location":"algorithms/dynamic-programming/","text":"Dynamic Programming Dynamic Programming (DP) is an algorithmic technique for solving complex problems by breaking them down into simpler subproblems and storing the results to avoid redundant calculations. Key Principles Optimal Substructure : An optimal solution contains optimal solutions to its subproblems Overlapping Subproblems : Same subproblems are solved multiple times Implementation Approaches 1. Top-Down (Memoization) // Fibonacci with memoization int fib(int n, vector<int>& memo) { if (n <= 1) return n; if (memo[n] != -1) return memo[n]; memo[n] = fib(n-1, memo) + fib(n-2, memo); return memo[n]; } int fibonacci(int n) { vector<int> memo(n+1, -1); return fib(n, memo); } 2. Bottom-Up (Tabulation) // Fibonacci with tabulation int fibonacci(int n) { if (n <= 1) return n; vector<int> dp(n+1); dp[0] = 0; dp[1] = 1; for (int i = 2; i <= n; i++) { dp[i] = dp[i-1] + dp[i-2]; } return dp[n]; } Classic DP Problems 1. Knapsack Problem // 0-1 Knapsack int knapsack(vector<int>& values, vector<int>& weights, int capacity) { int n = values.size(); vector<vector<int>> dp(n+1, vector<int>(capacity+1, 0)); for (int i = 1; i <= n; i++) { for (int w = 0; w <= capacity; w++) { if (weights[i-1] <= w) { dp[i][w] = max( values[i-1] + dp[i-1][w - weights[i-1]], // Take item dp[i-1][w] // Don't take item ); } else { dp[i][w] = dp[i-1][w]; // Can't take item } } } return dp[n][capacity]; } 2. Longest Common Subsequence int longestCommonSubsequence(string text1, string text2) { int m = text1.length(), n = text2.length(); vector<vector<int>> dp(m+1, vector<int>(n+1, 0)); for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (text1[i-1] == text2[j-1]) { dp[i][j] = dp[i-1][j-1] + 1; } else { dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } } } return dp[m][n]; } 3. Coin Change int coinChange(vector<int>& coins, int amount) { vector<int> dp(amount + 1, amount + 1); dp[0] = 0; for (int coin : coins) { for (int i = coin; i <= amount; i++) { dp[i] = min(dp[i], dp[i - coin] + 1); } } return dp[amount] > amount ? -1 : dp[amount]; } 4. Longest Increasing Subsequence int lengthOfLIS(vector<int>& nums) { int n = nums.size(); vector<int> dp(n, 1); for (int i = 0; i < n; i++) { for (int j = 0; j < i; j++) { if (nums[i] > nums[j]) { dp[i] = max(dp[i], dp[j] + 1); } } } return *max_element(dp.begin(), dp.end()); } 5. Edit Distance int minDistance(string word1, string word2) { int m = word1.length(), n = word2.length(); vector<vector<int>> dp(m+1, vector<int>(n+1, 0)); // Base cases for (int i = 0; i <= m; i++) dp[i][0] = i; for (int j = 0; j <= n; j++) dp[0][j] = j; for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (word1[i-1] == word2[j-1]) { dp[i][j] = dp[i-1][j-1]; } else { dp[i][j] = 1 + min({ dp[i-1][j], // Delete dp[i][j-1], // Insert dp[i-1][j-1] // Replace }); } } } return dp[m][n]; } Optimization Techniques 1. Space Optimization Often, DP solutions can be optimized from O(n\u00b2) to O(n) space by only storing the most recent rows/columns: // Fibonacci with O(1) space int fibonacci(int n) { if (n <= 1) return n; int prev = 0, curr = 1; for (int i = 2; i <= n; i++) { int next = prev + curr; prev = curr; curr = next; } return curr; } 2. State Compression For problems with boolean states, bit manipulation can optimize space: // Using bitmasks in DP int countWays(int n, int mask, vector<int>& dp) { if (mask == (1 << n) - 1) return 1; if (dp[mask] != -1) return dp[mask]; int ways = 0; for (int i = 0; i < n; i++) { if ((mask & (1 << i)) == 0) { ways += countWays(n, mask | (1 << i), dp); } } return dp[mask] = ways; } How to Approach DP Problems Identify if a problem can be solved with DP (optimal substructure, overlapping subproblems) Define state clearly (what does each dp[i] or dp[i][j] represent?) Establish recurrence relation (how to build solutions from smaller subproblems) Determine base cases Decide between top-down or bottom-up implementation Optimize for space if needed","title":"Dynamic Programming"},{"location":"algorithms/dynamic-programming/#dynamic-programming","text":"Dynamic Programming (DP) is an algorithmic technique for solving complex problems by breaking them down into simpler subproblems and storing the results to avoid redundant calculations.","title":"Dynamic Programming"},{"location":"algorithms/dynamic-programming/#key-principles","text":"Optimal Substructure : An optimal solution contains optimal solutions to its subproblems Overlapping Subproblems : Same subproblems are solved multiple times","title":"Key Principles"},{"location":"algorithms/dynamic-programming/#implementation-approaches","text":"","title":"Implementation Approaches"},{"location":"algorithms/dynamic-programming/#1-top-down-memoization","text":"// Fibonacci with memoization int fib(int n, vector<int>& memo) { if (n <= 1) return n; if (memo[n] != -1) return memo[n]; memo[n] = fib(n-1, memo) + fib(n-2, memo); return memo[n]; } int fibonacci(int n) { vector<int> memo(n+1, -1); return fib(n, memo); }","title":"1. Top-Down (Memoization)"},{"location":"algorithms/dynamic-programming/#2-bottom-up-tabulation","text":"// Fibonacci with tabulation int fibonacci(int n) { if (n <= 1) return n; vector<int> dp(n+1); dp[0] = 0; dp[1] = 1; for (int i = 2; i <= n; i++) { dp[i] = dp[i-1] + dp[i-2]; } return dp[n]; }","title":"2. Bottom-Up (Tabulation)"},{"location":"algorithms/dynamic-programming/#classic-dp-problems","text":"","title":"Classic DP Problems"},{"location":"algorithms/dynamic-programming/#1-knapsack-problem","text":"// 0-1 Knapsack int knapsack(vector<int>& values, vector<int>& weights, int capacity) { int n = values.size(); vector<vector<int>> dp(n+1, vector<int>(capacity+1, 0)); for (int i = 1; i <= n; i++) { for (int w = 0; w <= capacity; w++) { if (weights[i-1] <= w) { dp[i][w] = max( values[i-1] + dp[i-1][w - weights[i-1]], // Take item dp[i-1][w] // Don't take item ); } else { dp[i][w] = dp[i-1][w]; // Can't take item } } } return dp[n][capacity]; }","title":"1. Knapsack Problem"},{"location":"algorithms/dynamic-programming/#2-longest-common-subsequence","text":"int longestCommonSubsequence(string text1, string text2) { int m = text1.length(), n = text2.length(); vector<vector<int>> dp(m+1, vector<int>(n+1, 0)); for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (text1[i-1] == text2[j-1]) { dp[i][j] = dp[i-1][j-1] + 1; } else { dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } } } return dp[m][n]; }","title":"2. Longest Common Subsequence"},{"location":"algorithms/dynamic-programming/#3-coin-change","text":"int coinChange(vector<int>& coins, int amount) { vector<int> dp(amount + 1, amount + 1); dp[0] = 0; for (int coin : coins) { for (int i = coin; i <= amount; i++) { dp[i] = min(dp[i], dp[i - coin] + 1); } } return dp[amount] > amount ? -1 : dp[amount]; }","title":"3. Coin Change"},{"location":"algorithms/dynamic-programming/#4-longest-increasing-subsequence","text":"int lengthOfLIS(vector<int>& nums) { int n = nums.size(); vector<int> dp(n, 1); for (int i = 0; i < n; i++) { for (int j = 0; j < i; j++) { if (nums[i] > nums[j]) { dp[i] = max(dp[i], dp[j] + 1); } } } return *max_element(dp.begin(), dp.end()); }","title":"4. Longest Increasing Subsequence"},{"location":"algorithms/dynamic-programming/#5-edit-distance","text":"int minDistance(string word1, string word2) { int m = word1.length(), n = word2.length(); vector<vector<int>> dp(m+1, vector<int>(n+1, 0)); // Base cases for (int i = 0; i <= m; i++) dp[i][0] = i; for (int j = 0; j <= n; j++) dp[0][j] = j; for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (word1[i-1] == word2[j-1]) { dp[i][j] = dp[i-1][j-1]; } else { dp[i][j] = 1 + min({ dp[i-1][j], // Delete dp[i][j-1], // Insert dp[i-1][j-1] // Replace }); } } } return dp[m][n]; }","title":"5. Edit Distance"},{"location":"algorithms/dynamic-programming/#optimization-techniques","text":"","title":"Optimization Techniques"},{"location":"algorithms/dynamic-programming/#1-space-optimization","text":"Often, DP solutions can be optimized from O(n\u00b2) to O(n) space by only storing the most recent rows/columns: // Fibonacci with O(1) space int fibonacci(int n) { if (n <= 1) return n; int prev = 0, curr = 1; for (int i = 2; i <= n; i++) { int next = prev + curr; prev = curr; curr = next; } return curr; }","title":"1. Space Optimization"},{"location":"algorithms/dynamic-programming/#2-state-compression","text":"For problems with boolean states, bit manipulation can optimize space: // Using bitmasks in DP int countWays(int n, int mask, vector<int>& dp) { if (mask == (1 << n) - 1) return 1; if (dp[mask] != -1) return dp[mask]; int ways = 0; for (int i = 0; i < n; i++) { if ((mask & (1 << i)) == 0) { ways += countWays(n, mask | (1 << i), dp); } } return dp[mask] = ways; }","title":"2. State Compression"},{"location":"algorithms/dynamic-programming/#how-to-approach-dp-problems","text":"Identify if a problem can be solved with DP (optimal substructure, overlapping subproblems) Define state clearly (what does each dp[i] or dp[i][j] represent?) Establish recurrence relation (how to build solutions from smaller subproblems) Determine base cases Decide between top-down or bottom-up implementation Optimize for space if needed","title":"How to Approach DP Problems"},{"location":"algorithms/graph/","text":"Graph Algorithms A comprehensive guide to common graph algorithms with implementation details and use cases. Graph Representations Adjacency Matrix vector<vector<int>> graph(n, vector<int>(n, 0)); // Add edge from u to v graph[u][v] = 1; // For weighted graph: graph[u][v] = weight Pros: - O(1) lookup time to check if edge exists - Simple implementation for dense graphs Cons: - O(V\u00b2) space complexity - Inefficient for sparse graphs Adjacency List vector<vector<int>> graph(n); // Add edge from u to v graph[u].push_back(v); // For weighted graph: vector<vector<pair<int, int>>> graph(n); // Add edge from u to v with weight w graph[u].push_back({v, w}); Pros: - Space efficient for sparse graphs: O(V+E) - Faster to iterate over edges Cons: - O(degree(v)) time to check if edge exists - Less intuitive for dense graphs Graph Traversal Depth-First Search (DFS) void dfs(vector<vector<int>>& graph, int node, vector<bool>& visited) { visited[node] = true; cout << node << \" \"; for (int neighbor : graph[node]) { if (!visited[neighbor]) { dfs(graph, neighbor, visited); } } } void dfsTraversal(vector<vector<int>>& graph, int start) { int n = graph.size(); vector<bool> visited(n, false); dfs(graph, start, visited); } Time Complexity: O(V + E) Space Complexity: O(V) for the recursion stack Breadth-First Search (BFS) void bfs(vector<vector<int>>& graph, int start) { int n = graph.size(); vector<bool> visited(n, false); queue<int> q; visited[start] = true; q.push(start); while (!q.empty()) { int node = q.front(); q.pop(); cout << node << \" \"; for (int neighbor : graph[node]) { if (!visited[neighbor]) { visited[neighbor] = true; q.push(neighbor); } } } } Time Complexity: O(V + E) Space Complexity: O(V) for the queue Shortest Path Algorithms Dijkstra's Algorithm For finding shortest paths from a source to all vertices in a weighted graph with non-negative weights. vector<int> dijkstra(vector<vector<pair<int, int>>>& graph, int start) { int n = graph.size(); vector<int> dist(n, INT_MAX); dist[start] = 0; priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; pq.push({0, start}); while (!pq.empty()) { int u = pq.top().second; int d = pq.top().first; pq.pop(); if (d > dist[u]) continue; for (auto& edge : graph[u]) { int v = edge.first; int weight = edge.second; if (dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } } return dist; } Time Complexity: O(E log V) Bellman-Ford Algorithm For finding shortest paths from a source to all vertices, even with negative edge weights (but no negative cycles). vector<int> bellmanFord(int n, vector<vector<int>>& edges, int start) { vector<int> dist(n, INT_MAX); dist[start] = 0; // Relax all edges V-1 times for (int i = 0; i < n - 1; i++) { for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; } } } // Check for negative cycles for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) { cout << \"Graph contains negative weight cycle\" << endl; return {}; } } return dist; } Time Complexity: O(V * E) Floyd-Warshall Algorithm For finding shortest paths between all pairs of vertices. vector<vector<int>> floydWarshall(vector<vector<int>>& graph) { int n = graph.size(); vector<vector<int>> dist = graph; // Initialize the distance matrix for (int i = 0; i < n; i++) { for (int j = 0; j < n; j++) { if (i != j && dist[i][j] == 0) { dist[i][j] = INT_MAX; } } } // Update the shortest path for all pairs of vertices for (int k = 0; k < n; k++) { for (int i = 0; i < n; i++) { for (int j = 0; j < n; j++) { if (dist[i][k] != INT_MAX && dist[k][j] != INT_MAX && dist[i][k] + dist[k][j] < dist[i][j]) { dist[i][j] = dist[i][k] + dist[k][j]; } } } } return dist; } Time Complexity: O(V\u00b3) Minimum Spanning Tree Kruskal's Algorithm int kruskalMST(int n, vector<vector<int>>& edges) { // Sort edges by weight sort(edges.begin(), edges.end(), [](const vector<int>& a, const vector<int>& b) { return a[2] < b[2]; }); // Initialize disjoint set vector<int> parent(n); vector<int> rank(n, 0); for (int i = 0; i < n; i++) { parent[i] = i; } function<int(int)> find = [&](int x) { if (parent[x] != x) { parent[x] = find(parent[x]); } return parent[x]; }; auto unionSets = [&](int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX == rootY) return false; if (rank[rootX] < rank[rootY]) { parent[rootX] = rootY; } else if (rank[rootX] > rank[rootY]) { parent[rootY] = rootX; } else { parent[rootY] = rootX; rank[rootX]++; } return true; }; int totalWeight = 0; int edgesAdded = 0; for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (unionSets(u, v)) { totalWeight += weight; edgesAdded++; if (edgesAdded == n - 1) break; } } return totalWeight; } Time Complexity: O(E log E) Prim's Algorithm int primMST(vector<vector<pair<int, int>>>& graph) { int n = graph.size(); vector<bool> inMST(n, false); vector<int> key(n, INT_MAX); priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; key[0] = 0; pq.push({0, 0}); // {weight, vertex} int totalWeight = 0; while (!pq.empty()) { int u = pq.top().second; int weight = pq.top().first; pq.pop(); if (inMST[u]) continue; inMST[u] = true; totalWeight += weight; for (auto& neighbor : graph[u]) { int v = neighbor.first; int w = neighbor.second; if (!inMST[v] && w < key[v]) { key[v] = w; pq.push({key[v], v}); } } } return totalWeight; } Time Complexity: O(E log V) Strongly Connected Components Kosaraju's Algorithm void dfs(vector<vector<int>>& graph, int node, vector<bool>& visited, vector<int>& order) { visited[node] = true; for (int neighbor : graph[node]) { if (!visited[neighbor]) { dfs(graph, neighbor, visited, order); } } order.push_back(node); } void dfsReverse(vector<vector<int>>& reversedGraph, int node, vector<bool>& visited, vector<int>& component) { visited[node] = true; component.push_back(node); for (int neighbor : reversedGraph[node]) { if (!visited[neighbor]) { dfsReverse(reversedGraph, neighbor, visited, component); } } } vector<vector<int>> kosarajuSCC(vector<vector<int>>& graph) { int n = graph.size(); vector<bool> visited(n, false); vector<int> order; // Step 1: DFS and record finish order for (int i = 0; i < n; i++) { if (!visited[i]) { dfs(graph, i, visited, order); } } // Step 2: Reverse the graph vector<vector<int>> reversedGraph(n); for (int u = 0; u < n; u++) { for (int v : graph[u]) { reversedGraph[v].push_back(u); } } // Step 3: DFS on reversed graph in finish order fill(visited.begin(), visited.end(), false); vector<vector<int>> scc; for (int i = n - 1; i >= 0; i--) { int node = order[i]; if (!visited[node]) { vector<int> component; dfsReverse(reversedGraph, node, visited, component); scc.push_back(component); } } return scc; } Time Complexity: O(V + E) Space Complexity: O(V) for the recursion stack and visited array","title":"Graphs"},{"location":"algorithms/graph/#graph-algorithms","text":"A comprehensive guide to common graph algorithms with implementation details and use cases.","title":"Graph Algorithms"},{"location":"algorithms/graph/#graph-representations","text":"","title":"Graph Representations"},{"location":"algorithms/graph/#adjacency-matrix","text":"vector<vector<int>> graph(n, vector<int>(n, 0)); // Add edge from u to v graph[u][v] = 1; // For weighted graph: graph[u][v] = weight Pros: - O(1) lookup time to check if edge exists - Simple implementation for dense graphs Cons: - O(V\u00b2) space complexity - Inefficient for sparse graphs","title":"Adjacency Matrix"},{"location":"algorithms/graph/#adjacency-list","text":"vector<vector<int>> graph(n); // Add edge from u to v graph[u].push_back(v); // For weighted graph: vector<vector<pair<int, int>>> graph(n); // Add edge from u to v with weight w graph[u].push_back({v, w}); Pros: - Space efficient for sparse graphs: O(V+E) - Faster to iterate over edges Cons: - O(degree(v)) time to check if edge exists - Less intuitive for dense graphs","title":"Adjacency List"},{"location":"algorithms/graph/#graph-traversal","text":"","title":"Graph Traversal"},{"location":"algorithms/graph/#depth-first-search-dfs","text":"void dfs(vector<vector<int>>& graph, int node, vector<bool>& visited) { visited[node] = true; cout << node << \" \"; for (int neighbor : graph[node]) { if (!visited[neighbor]) { dfs(graph, neighbor, visited); } } } void dfsTraversal(vector<vector<int>>& graph, int start) { int n = graph.size(); vector<bool> visited(n, false); dfs(graph, start, visited); } Time Complexity: O(V + E) Space Complexity: O(V) for the recursion stack","title":"Depth-First Search (DFS)"},{"location":"algorithms/graph/#breadth-first-search-bfs","text":"void bfs(vector<vector<int>>& graph, int start) { int n = graph.size(); vector<bool> visited(n, false); queue<int> q; visited[start] = true; q.push(start); while (!q.empty()) { int node = q.front(); q.pop(); cout << node << \" \"; for (int neighbor : graph[node]) { if (!visited[neighbor]) { visited[neighbor] = true; q.push(neighbor); } } } } Time Complexity: O(V + E) Space Complexity: O(V) for the queue","title":"Breadth-First Search (BFS)"},{"location":"algorithms/graph/#shortest-path-algorithms","text":"","title":"Shortest Path Algorithms"},{"location":"algorithms/graph/#dijkstras-algorithm","text":"For finding shortest paths from a source to all vertices in a weighted graph with non-negative weights. vector<int> dijkstra(vector<vector<pair<int, int>>>& graph, int start) { int n = graph.size(); vector<int> dist(n, INT_MAX); dist[start] = 0; priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; pq.push({0, start}); while (!pq.empty()) { int u = pq.top().second; int d = pq.top().first; pq.pop(); if (d > dist[u]) continue; for (auto& edge : graph[u]) { int v = edge.first; int weight = edge.second; if (dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } } return dist; } Time Complexity: O(E log V)","title":"Dijkstra's Algorithm"},{"location":"algorithms/graph/#bellman-ford-algorithm","text":"For finding shortest paths from a source to all vertices, even with negative edge weights (but no negative cycles). vector<int> bellmanFord(int n, vector<vector<int>>& edges, int start) { vector<int> dist(n, INT_MAX); dist[start] = 0; // Relax all edges V-1 times for (int i = 0; i < n - 1; i++) { for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; } } } // Check for negative cycles for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) { cout << \"Graph contains negative weight cycle\" << endl; return {}; } } return dist; } Time Complexity: O(V * E)","title":"Bellman-Ford Algorithm"},{"location":"algorithms/graph/#floyd-warshall-algorithm","text":"For finding shortest paths between all pairs of vertices. vector<vector<int>> floydWarshall(vector<vector<int>>& graph) { int n = graph.size(); vector<vector<int>> dist = graph; // Initialize the distance matrix for (int i = 0; i < n; i++) { for (int j = 0; j < n; j++) { if (i != j && dist[i][j] == 0) { dist[i][j] = INT_MAX; } } } // Update the shortest path for all pairs of vertices for (int k = 0; k < n; k++) { for (int i = 0; i < n; i++) { for (int j = 0; j < n; j++) { if (dist[i][k] != INT_MAX && dist[k][j] != INT_MAX && dist[i][k] + dist[k][j] < dist[i][j]) { dist[i][j] = dist[i][k] + dist[k][j]; } } } } return dist; } Time Complexity: O(V\u00b3)","title":"Floyd-Warshall Algorithm"},{"location":"algorithms/graph/#minimum-spanning-tree","text":"","title":"Minimum Spanning Tree"},{"location":"algorithms/graph/#kruskals-algorithm","text":"int kruskalMST(int n, vector<vector<int>>& edges) { // Sort edges by weight sort(edges.begin(), edges.end(), [](const vector<int>& a, const vector<int>& b) { return a[2] < b[2]; }); // Initialize disjoint set vector<int> parent(n); vector<int> rank(n, 0); for (int i = 0; i < n; i++) { parent[i] = i; } function<int(int)> find = [&](int x) { if (parent[x] != x) { parent[x] = find(parent[x]); } return parent[x]; }; auto unionSets = [&](int x, int y) { int rootX = find(x); int rootY = find(y); if (rootX == rootY) return false; if (rank[rootX] < rank[rootY]) { parent[rootX] = rootY; } else if (rank[rootX] > rank[rootY]) { parent[rootY] = rootX; } else { parent[rootY] = rootX; rank[rootX]++; } return true; }; int totalWeight = 0; int edgesAdded = 0; for (auto& edge : edges) { int u = edge[0]; int v = edge[1]; int weight = edge[2]; if (unionSets(u, v)) { totalWeight += weight; edgesAdded++; if (edgesAdded == n - 1) break; } } return totalWeight; } Time Complexity: O(E log E)","title":"Kruskal's Algorithm"},{"location":"algorithms/graph/#prims-algorithm","text":"int primMST(vector<vector<pair<int, int>>>& graph) { int n = graph.size(); vector<bool> inMST(n, false); vector<int> key(n, INT_MAX); priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; key[0] = 0; pq.push({0, 0}); // {weight, vertex} int totalWeight = 0; while (!pq.empty()) { int u = pq.top().second; int weight = pq.top().first; pq.pop(); if (inMST[u]) continue; inMST[u] = true; totalWeight += weight; for (auto& neighbor : graph[u]) { int v = neighbor.first; int w = neighbor.second; if (!inMST[v] && w < key[v]) { key[v] = w; pq.push({key[v], v}); } } } return totalWeight; } Time Complexity: O(E log V)","title":"Prim's Algorithm"},{"location":"algorithms/graph/#strongly-connected-components","text":"","title":"Strongly Connected Components"},{"location":"algorithms/graph/#kosarajus-algorithm","text":"void dfs(vector<vector<int>>& graph, int node, vector<bool>& visited, vector<int>& order) { visited[node] = true; for (int neighbor : graph[node]) { if (!visited[neighbor]) { dfs(graph, neighbor, visited, order); } } order.push_back(node); } void dfsReverse(vector<vector<int>>& reversedGraph, int node, vector<bool>& visited, vector<int>& component) { visited[node] = true; component.push_back(node); for (int neighbor : reversedGraph[node]) { if (!visited[neighbor]) { dfsReverse(reversedGraph, neighbor, visited, component); } } } vector<vector<int>> kosarajuSCC(vector<vector<int>>& graph) { int n = graph.size(); vector<bool> visited(n, false); vector<int> order; // Step 1: DFS and record finish order for (int i = 0; i < n; i++) { if (!visited[i]) { dfs(graph, i, visited, order); } } // Step 2: Reverse the graph vector<vector<int>> reversedGraph(n); for (int u = 0; u < n; u++) { for (int v : graph[u]) { reversedGraph[v].push_back(u); } } // Step 3: DFS on reversed graph in finish order fill(visited.begin(), visited.end(), false); vector<vector<int>> scc; for (int i = n - 1; i >= 0; i--) { int node = order[i]; if (!visited[node]) { vector<int> component; dfsReverse(reversedGraph, node, visited, component); scc.push_back(component); } } return scc; } Time Complexity: O(V + E) Space Complexity: O(V) for the recursion stack and visited array","title":"Kosaraju's Algorithm"},{"location":"algorithms/greedy/","text":"Greedy Algorithms Greedy algorithms make locally optimal choices at each step with the hope of finding a global optimum. They are typically used for optimization problems. Characteristics of Greedy Algorithms Greedy Choice Property : A global optimum can be reached by making locally optimal choices. Optimal Substructure : An optimal solution contains optimal solutions to its subproblems. Simple Implementation : Usually easier to implement compared to other techniques. No Backtracking : Once a decision is made, it is never reconsidered. Common Greedy Problems 1. Coin Change (with specific coin systems) For coin systems like US currency (1, 5, 10, 25), a greedy approach works. vector<int> greedyCoinChange(int amount, vector<int>& coins) { // Sort coins in descending order sort(coins.rbegin(), coins.rend()); vector<int> result; for (int coin : coins) { while (amount >= coin) { result.push_back(coin); amount -= coin; } } return result; } Note : This doesn't work for all coin systems. For example, with coins {1, 3, 4} and amount 6, the optimal solution is two 3's, not a 4 and two 1's. 2. Activity Selection Select the maximum number of activities that don't overlap. vector<int> activitySelection(vector<pair<int, int>>& activities) { // Sort by end time sort(activities.begin(), activities.end(), [](pair<int, int>& a, pair<int, int>& b) { return a.second < b.second; }); vector<int> selected; selected.push_back(0); // First activity is always selected int lastEnd = activities[0].second; for (int i = 1; i < activities.size(); i++) { // If this activity starts after the last selected activity ends if (activities[i].first >= lastEnd) { selected.push_back(i); lastEnd = activities[i].second; } } return selected; } 3. Fractional Knapsack Unlike 0/1 Knapsack, we can take fractions of items. double fractionalKnapsack(vector<int>& values, vector<int>& weights, int capacity) { int n = values.size(); vector<pair<double, int>> valuePerWeight(n); for (int i = 0; i < n; i++) { valuePerWeight[i] = {(double)values[i] / weights[i], i}; } // Sort by value per weight in descending order sort(valuePerWeight.rbegin(), valuePerWeight.rend()); double totalValue = 0.0; for (auto& [ratio, index] : valuePerWeight) { if (capacity >= weights[index]) { // Take the whole item totalValue += values[index]; capacity -= weights[index]; } else { // Take a fraction of the item totalValue += values[index] * ((double)capacity / weights[index]); break; } } return totalValue; } 4. Huffman Coding A lossless data compression algorithm. struct Node { char data; int freq; Node *left, *right; Node(char data, int freq) : data(data), freq(freq), left(nullptr), right(nullptr) {} }; struct Compare { bool operator()(Node* a, Node* b) { return a->freq > b->freq; } }; unordered_map<char, string> huffmanCodes; void generateCodes(Node* root, string code) { if (!root) return; if (root->data != '\\0') { huffmanCodes[root->data] = code; } generateCodes(root->left, code + \"0\"); generateCodes(root->right, code + \"1\"); } void huffmanCoding(string text) { unordered_map<char, int> freq; for (char c : text) { freq[c]++; } priority_queue<Node*, vector<Node*>, Compare> pq; for (auto& pair : freq) { pq.push(new Node(pair.first, pair.second)); } while (pq.size() > 1) { Node* left = pq.top(); pq.pop(); Node* right = pq.top(); pq.pop(); Node* parent = new Node('\\0', left->freq + right->freq); parent->left = left; parent->right = right; pq.push(parent); } Node* root = pq.top(); generateCodes(root, \"\"); cout << \"Huffman Codes:\" << endl; for (auto& pair : huffmanCodes) { cout << pair.first << \": \" << pair.second << endl; } } 5. Minimum Spanning Tree (Prim's Algorithm) int primMST(vector<vector<pair<int, int>>>& graph) { int n = graph.size(); vector<bool> inMST(n, false); vector<int> key(n, INT_MAX); priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; key[0] = 0; pq.push({0, 0}); // {weight, vertex} int totalWeight = 0; while (!pq.empty()) { int u = pq.top().second; int weight = pq.top().first; pq.pop(); if (inMST[u]) continue; inMST[u] = true; totalWeight += weight; for (auto& [v, w] : graph[u]) { if (!inMST[v] && w < key[v]) { key[v] = w; pq.push({key[v], v}); } } } return totalWeight; } 6. Dijkstra's Algorithm (Shortest Path) vector<int> dijkstra(vector<vector<pair<int, int>>>& graph, int start) { int n = graph.size(); vector<int> dist(n, INT_MAX); dist[start] = 0; priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; pq.push({0, start}); while (!pq.empty()) { int u = pq.top().second; int d = pq.top().first; pq.pop(); if (d > dist[u]) continue; for (auto& [v, weight] : graph[u]) { if (dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } } return dist; } 7. Job Sequencing with Deadlines struct Job { int id, deadline, profit; }; vector<int> jobSequencing(vector<Job>& jobs) { // Sort jobs by profit in descending order sort(jobs.begin(), jobs.end(), [](Job& a, Job& b) { return a.profit > b.profit; }); // Find the maximum deadline int maxDeadline = 0; for (Job& job : jobs) { maxDeadline = max(maxDeadline, job.deadline); } vector<int> slot(maxDeadline + 1, -1); vector<int> sequence; int totalProfit = 0; for (Job& job : jobs) { // Find a free slot before the deadline for (int i = job.deadline; i > 0; i--) { if (slot[i] == -1) { slot[i] = job.id; totalProfit += job.profit; sequence.push_back(job.id); break; } } } cout << \"Total profit: \" << totalProfit << endl; return sequence; } When to Use Greedy Algorithms Greedy algorithms are appropriate when: The problem has optimal substructure The greedy choice is consistent with global optimal Local optimizations lead to global optimization Advantages of Greedy Algorithms Simple and intuitive Often efficient (typically O(n log n) due to sorting) Doesn't require looking at all possibilities Disadvantages of Greedy Algorithms Doesn't always yield the optimal solution Difficult to prove correctness (requires mathematical proof) Short-sighted approach might miss better solutions Greedy vs. Dynamic Programming Greedy Dynamic Programming Makes locally optimal choices Considers all possible choices No guarantee of global optimum Always finds the global optimum Typically faster Typically slower but more thorough No overlapping subproblems needed Relies on overlapping subproblems No memorization Uses memoization or tabulation Examples: Fractional Knapsack Examples: 0/1 Knapsack When Greedy Fails: Counterexamples Coin Change : For denominations {1, 3, 4} and amount 6, greedy gives {4, 1, 1} (3 coins), but optimal is {3, 3} (2 coins). 0/1 Knapsack : Choosing items by value/weight ratio doesn't always yield optimal solution. Real-World Applications Network routing protocols Data compression (Huffman coding) Task scheduling Resource allocation Load balancing in distributed systems","title":"Greedy"},{"location":"algorithms/greedy/#greedy-algorithms","text":"Greedy algorithms make locally optimal choices at each step with the hope of finding a global optimum. They are typically used for optimization problems.","title":"Greedy Algorithms"},{"location":"algorithms/greedy/#characteristics-of-greedy-algorithms","text":"Greedy Choice Property : A global optimum can be reached by making locally optimal choices. Optimal Substructure : An optimal solution contains optimal solutions to its subproblems. Simple Implementation : Usually easier to implement compared to other techniques. No Backtracking : Once a decision is made, it is never reconsidered.","title":"Characteristics of Greedy Algorithms"},{"location":"algorithms/greedy/#common-greedy-problems","text":"","title":"Common Greedy Problems"},{"location":"algorithms/greedy/#1-coin-change-with-specific-coin-systems","text":"For coin systems like US currency (1, 5, 10, 25), a greedy approach works. vector<int> greedyCoinChange(int amount, vector<int>& coins) { // Sort coins in descending order sort(coins.rbegin(), coins.rend()); vector<int> result; for (int coin : coins) { while (amount >= coin) { result.push_back(coin); amount -= coin; } } return result; } Note : This doesn't work for all coin systems. For example, with coins {1, 3, 4} and amount 6, the optimal solution is two 3's, not a 4 and two 1's.","title":"1. Coin Change (with specific coin systems)"},{"location":"algorithms/greedy/#2-activity-selection","text":"Select the maximum number of activities that don't overlap. vector<int> activitySelection(vector<pair<int, int>>& activities) { // Sort by end time sort(activities.begin(), activities.end(), [](pair<int, int>& a, pair<int, int>& b) { return a.second < b.second; }); vector<int> selected; selected.push_back(0); // First activity is always selected int lastEnd = activities[0].second; for (int i = 1; i < activities.size(); i++) { // If this activity starts after the last selected activity ends if (activities[i].first >= lastEnd) { selected.push_back(i); lastEnd = activities[i].second; } } return selected; }","title":"2. Activity Selection"},{"location":"algorithms/greedy/#3-fractional-knapsack","text":"Unlike 0/1 Knapsack, we can take fractions of items. double fractionalKnapsack(vector<int>& values, vector<int>& weights, int capacity) { int n = values.size(); vector<pair<double, int>> valuePerWeight(n); for (int i = 0; i < n; i++) { valuePerWeight[i] = {(double)values[i] / weights[i], i}; } // Sort by value per weight in descending order sort(valuePerWeight.rbegin(), valuePerWeight.rend()); double totalValue = 0.0; for (auto& [ratio, index] : valuePerWeight) { if (capacity >= weights[index]) { // Take the whole item totalValue += values[index]; capacity -= weights[index]; } else { // Take a fraction of the item totalValue += values[index] * ((double)capacity / weights[index]); break; } } return totalValue; }","title":"3. Fractional Knapsack"},{"location":"algorithms/greedy/#4-huffman-coding","text":"A lossless data compression algorithm. struct Node { char data; int freq; Node *left, *right; Node(char data, int freq) : data(data), freq(freq), left(nullptr), right(nullptr) {} }; struct Compare { bool operator()(Node* a, Node* b) { return a->freq > b->freq; } }; unordered_map<char, string> huffmanCodes; void generateCodes(Node* root, string code) { if (!root) return; if (root->data != '\\0') { huffmanCodes[root->data] = code; } generateCodes(root->left, code + \"0\"); generateCodes(root->right, code + \"1\"); } void huffmanCoding(string text) { unordered_map<char, int> freq; for (char c : text) { freq[c]++; } priority_queue<Node*, vector<Node*>, Compare> pq; for (auto& pair : freq) { pq.push(new Node(pair.first, pair.second)); } while (pq.size() > 1) { Node* left = pq.top(); pq.pop(); Node* right = pq.top(); pq.pop(); Node* parent = new Node('\\0', left->freq + right->freq); parent->left = left; parent->right = right; pq.push(parent); } Node* root = pq.top(); generateCodes(root, \"\"); cout << \"Huffman Codes:\" << endl; for (auto& pair : huffmanCodes) { cout << pair.first << \": \" << pair.second << endl; } }","title":"4. Huffman Coding"},{"location":"algorithms/greedy/#5-minimum-spanning-tree-prims-algorithm","text":"int primMST(vector<vector<pair<int, int>>>& graph) { int n = graph.size(); vector<bool> inMST(n, false); vector<int> key(n, INT_MAX); priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; key[0] = 0; pq.push({0, 0}); // {weight, vertex} int totalWeight = 0; while (!pq.empty()) { int u = pq.top().second; int weight = pq.top().first; pq.pop(); if (inMST[u]) continue; inMST[u] = true; totalWeight += weight; for (auto& [v, w] : graph[u]) { if (!inMST[v] && w < key[v]) { key[v] = w; pq.push({key[v], v}); } } } return totalWeight; }","title":"5. Minimum Spanning Tree (Prim's Algorithm)"},{"location":"algorithms/greedy/#6-dijkstras-algorithm-shortest-path","text":"vector<int> dijkstra(vector<vector<pair<int, int>>>& graph, int start) { int n = graph.size(); vector<int> dist(n, INT_MAX); dist[start] = 0; priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq; pq.push({0, start}); while (!pq.empty()) { int u = pq.top().second; int d = pq.top().first; pq.pop(); if (d > dist[u]) continue; for (auto& [v, weight] : graph[u]) { if (dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; pq.push({dist[v], v}); } } } return dist; }","title":"6. Dijkstra's Algorithm (Shortest Path)"},{"location":"algorithms/greedy/#7-job-sequencing-with-deadlines","text":"struct Job { int id, deadline, profit; }; vector<int> jobSequencing(vector<Job>& jobs) { // Sort jobs by profit in descending order sort(jobs.begin(), jobs.end(), [](Job& a, Job& b) { return a.profit > b.profit; }); // Find the maximum deadline int maxDeadline = 0; for (Job& job : jobs) { maxDeadline = max(maxDeadline, job.deadline); } vector<int> slot(maxDeadline + 1, -1); vector<int> sequence; int totalProfit = 0; for (Job& job : jobs) { // Find a free slot before the deadline for (int i = job.deadline; i > 0; i--) { if (slot[i] == -1) { slot[i] = job.id; totalProfit += job.profit; sequence.push_back(job.id); break; } } } cout << \"Total profit: \" << totalProfit << endl; return sequence; }","title":"7. Job Sequencing with Deadlines"},{"location":"algorithms/greedy/#when-to-use-greedy-algorithms","text":"Greedy algorithms are appropriate when: The problem has optimal substructure The greedy choice is consistent with global optimal Local optimizations lead to global optimization","title":"When to Use Greedy Algorithms"},{"location":"algorithms/greedy/#advantages-of-greedy-algorithms","text":"Simple and intuitive Often efficient (typically O(n log n) due to sorting) Doesn't require looking at all possibilities","title":"Advantages of Greedy Algorithms"},{"location":"algorithms/greedy/#disadvantages-of-greedy-algorithms","text":"Doesn't always yield the optimal solution Difficult to prove correctness (requires mathematical proof) Short-sighted approach might miss better solutions","title":"Disadvantages of Greedy Algorithms"},{"location":"algorithms/greedy/#greedy-vs-dynamic-programming","text":"Greedy Dynamic Programming Makes locally optimal choices Considers all possible choices No guarantee of global optimum Always finds the global optimum Typically faster Typically slower but more thorough No overlapping subproblems needed Relies on overlapping subproblems No memorization Uses memoization or tabulation Examples: Fractional Knapsack Examples: 0/1 Knapsack","title":"Greedy vs. Dynamic Programming"},{"location":"algorithms/greedy/#when-greedy-fails-counterexamples","text":"Coin Change : For denominations {1, 3, 4} and amount 6, greedy gives {4, 1, 1} (3 coins), but optimal is {3, 3} (2 coins). 0/1 Knapsack : Choosing items by value/weight ratio doesn't always yield optimal solution.","title":"When Greedy Fails: Counterexamples"},{"location":"algorithms/greedy/#real-world-applications","text":"Network routing protocols Data compression (Huffman coding) Task scheduling Resource allocation Load balancing in distributed systems","title":"Real-World Applications"},{"location":"algorithms/math/","text":"Mathematical Algorithms This section covers essential mathematical algorithms frequently used in competitive programming and software engineering. Number Theory GCD and LCM // Greatest Common Divisor using Euclidean algorithm int gcd(int a, int b) { return b == 0 ? a : gcd(b, a % b); } // Least Common Multiple int lcm(int a, int b) { return (a / gcd(a, b)) * b; // Avoid overflow: a * b / gcd(a, b) } Prime Numbers Sieve of Eratosthenes vector<bool> sieveOfEratosthenes(int n) { vector<bool> isPrime(n + 1, true); isPrime[0] = isPrime[1] = false; for (int i = 2; i * i <= n; i++) { if (isPrime[i]) { for (int j = i * i; j <= n; j += i) { isPrime[j] = false; } } } return isPrime; } // Get all primes up to n vector<int> getPrimes(int n) { vector<bool> isPrime = sieveOfEratosthenes(n); vector<int> primes; for (int i = 2; i <= n; i++) { if (isPrime[i]) { primes.push_back(i); } } return primes; } Time Complexity: O(n log log n) Primality Test bool isPrime(int n) { if (n <= 1) return false; if (n <= 3) return true; if (n % 2 == 0 || n % 3 == 0) return false; for (int i = 5; i * i <= n; i += 6) { if (n % i == 0 || n % (i + 2) == 0) { return false; } } return true; } Time Complexity: O(\u221an) Prime Factorization vector<int> primeFactorization(int n) { vector<int> factors; // Handle 2 separately while (n % 2 == 0) { factors.push_back(2); n /= 2; } // Check odd factors for (int i = 3; i * i <= n; i += 2) { while (n % i == 0) { factors.push_back(i); n /= i; } } // If n is a prime number greater than 2 if (n > 2) { factors.push_back(n); } return factors; } Time Complexity: O(\u221an) Modular Arithmetic // Addition under modulo int modAdd(int a, int b, int mod) { return (a % mod + b % mod) % mod; } // Subtraction under modulo int modSub(int a, int b, int mod) { return ((a % mod - b % mod) % mod + mod) % mod; // Handle negative result } // Multiplication under modulo int modMul(int a, int b, int mod) { return ((long long)a % mod * b % mod) % mod; } // Modular exponentiation: a^b % mod int modPow(int a, int b, int mod) { if (b == 0) return 1; long long res = modPow(a, b / 2, mod); res = (res * res) % mod; return (b % 2 == 0) ? res : (res * a) % mod; } // Modular inverse using Fermat's Little Theorem (works when mod is prime) int modInverse(int a, int mod) { return modPow(a, mod - 2, mod); } Combinatorics Factorial // Calculate n! (factorial) long long factorial(int n) { long long result = 1; for (int i = 2; i <= n; i++) { result *= i; } return result; } // Factorial with modulo long long modFactorial(int n, int mod) { long long result = 1; for (int i = 2; i <= n; i++) { result = (result * i) % mod; } return result; } Binomial Coefficients (nCr) // nCr = n! / (r! * (n-r)!) long long binomialCoefficient(int n, int r) { if (r > n - r) r = n - r; // nCr = nC(n-r) long long result = 1; for (int i = 0; i < r; i++) { result *= (n - i); result /= (i + 1); } return result; } // Binomial coefficient with modulo long long modBinomialCoefficient(int n, int r, int mod) { if (r > n - r) r = n - r; long long result = 1; for (int i = 0; i < r; i++) { result = (result * (n - i)) % mod; result = (result * modInverse(i + 1, mod)) % mod; } return result; } Permutations (nPr) // nPr = n! / (n-r)! long long permutation(int n, int r) { long long result = 1; for (int i = n - r + 1; i <= n; i++) { result *= i; } return result; } Matrix Operations Matrix Multiplication vector<vector<int>> matrixMultiply(const vector<vector<int>>& A, const vector<vector<int>>& B) { int n = A.size(); int m = A[0].size(); int p = B[0].size(); vector<vector<int>> C(n, vector<int>(p, 0)); for (int i = 0; i < n; i++) { for (int j = 0; j < p; j++) { for (int k = 0; k < m; k++) { C[i][j] += A[i][k] * B[k][j]; } } } return C; } Time Complexity: O(n\u00b3) Matrix Exponentiation vector<vector<int>> matrixPow(vector<vector<int>> A, int power) { int n = A.size(); // Initialize result to identity matrix vector<vector<int>> result(n, vector<int>(n, 0)); for (int i = 0; i < n; i++) { result[i][i] = 1; } while (power > 0) { if (power & 1) { result = matrixMultiply(result, A); } A = matrixMultiply(A, A); power >>= 1; } return result; } Time Complexity: O(n\u00b3 log power) Geometric Algorithms Distance between Points double distance(double x1, double y1, double x2, double y2) { return sqrt(pow(x2 - x1, 2) + pow(y2 - y1, 2)); } Area of Triangle // Using coordinates double triangleArea(double x1, double y1, double x2, double y2, double x3, double y3) { return 0.5 * abs(x1 * (y2 - y3) + x2 * (y3 - y1) + x3 * (y1 - y2)); } // Using sides (Heron's formula) double triangleArea(double a, double b, double c) { double s = (a + b + c) / 2; return sqrt(s * (s - a) * (s - b) * (s - c)); }","title":"Math"},{"location":"algorithms/math/#mathematical-algorithms","text":"This section covers essential mathematical algorithms frequently used in competitive programming and software engineering.","title":"Mathematical Algorithms"},{"location":"algorithms/math/#number-theory","text":"","title":"Number Theory"},{"location":"algorithms/math/#gcd-and-lcm","text":"// Greatest Common Divisor using Euclidean algorithm int gcd(int a, int b) { return b == 0 ? a : gcd(b, a % b); } // Least Common Multiple int lcm(int a, int b) { return (a / gcd(a, b)) * b; // Avoid overflow: a * b / gcd(a, b) }","title":"GCD and LCM"},{"location":"algorithms/math/#prime-numbers","text":"","title":"Prime Numbers"},{"location":"algorithms/math/#sieve-of-eratosthenes","text":"vector<bool> sieveOfEratosthenes(int n) { vector<bool> isPrime(n + 1, true); isPrime[0] = isPrime[1] = false; for (int i = 2; i * i <= n; i++) { if (isPrime[i]) { for (int j = i * i; j <= n; j += i) { isPrime[j] = false; } } } return isPrime; } // Get all primes up to n vector<int> getPrimes(int n) { vector<bool> isPrime = sieveOfEratosthenes(n); vector<int> primes; for (int i = 2; i <= n; i++) { if (isPrime[i]) { primes.push_back(i); } } return primes; } Time Complexity: O(n log log n)","title":"Sieve of Eratosthenes"},{"location":"algorithms/math/#primality-test","text":"bool isPrime(int n) { if (n <= 1) return false; if (n <= 3) return true; if (n % 2 == 0 || n % 3 == 0) return false; for (int i = 5; i * i <= n; i += 6) { if (n % i == 0 || n % (i + 2) == 0) { return false; } } return true; } Time Complexity: O(\u221an)","title":"Primality Test"},{"location":"algorithms/math/#prime-factorization","text":"vector<int> primeFactorization(int n) { vector<int> factors; // Handle 2 separately while (n % 2 == 0) { factors.push_back(2); n /= 2; } // Check odd factors for (int i = 3; i * i <= n; i += 2) { while (n % i == 0) { factors.push_back(i); n /= i; } } // If n is a prime number greater than 2 if (n > 2) { factors.push_back(n); } return factors; } Time Complexity: O(\u221an)","title":"Prime Factorization"},{"location":"algorithms/math/#modular-arithmetic","text":"// Addition under modulo int modAdd(int a, int b, int mod) { return (a % mod + b % mod) % mod; } // Subtraction under modulo int modSub(int a, int b, int mod) { return ((a % mod - b % mod) % mod + mod) % mod; // Handle negative result } // Multiplication under modulo int modMul(int a, int b, int mod) { return ((long long)a % mod * b % mod) % mod; } // Modular exponentiation: a^b % mod int modPow(int a, int b, int mod) { if (b == 0) return 1; long long res = modPow(a, b / 2, mod); res = (res * res) % mod; return (b % 2 == 0) ? res : (res * a) % mod; } // Modular inverse using Fermat's Little Theorem (works when mod is prime) int modInverse(int a, int mod) { return modPow(a, mod - 2, mod); }","title":"Modular Arithmetic"},{"location":"algorithms/math/#combinatorics","text":"","title":"Combinatorics"},{"location":"algorithms/math/#factorial","text":"// Calculate n! (factorial) long long factorial(int n) { long long result = 1; for (int i = 2; i <= n; i++) { result *= i; } return result; } // Factorial with modulo long long modFactorial(int n, int mod) { long long result = 1; for (int i = 2; i <= n; i++) { result = (result * i) % mod; } return result; }","title":"Factorial"},{"location":"algorithms/math/#binomial-coefficients-ncr","text":"// nCr = n! / (r! * (n-r)!) long long binomialCoefficient(int n, int r) { if (r > n - r) r = n - r; // nCr = nC(n-r) long long result = 1; for (int i = 0; i < r; i++) { result *= (n - i); result /= (i + 1); } return result; } // Binomial coefficient with modulo long long modBinomialCoefficient(int n, int r, int mod) { if (r > n - r) r = n - r; long long result = 1; for (int i = 0; i < r; i++) { result = (result * (n - i)) % mod; result = (result * modInverse(i + 1, mod)) % mod; } return result; }","title":"Binomial Coefficients (nCr)"},{"location":"algorithms/math/#permutations-npr","text":"// nPr = n! / (n-r)! long long permutation(int n, int r) { long long result = 1; for (int i = n - r + 1; i <= n; i++) { result *= i; } return result; }","title":"Permutations (nPr)"},{"location":"algorithms/math/#matrix-operations","text":"","title":"Matrix Operations"},{"location":"algorithms/math/#matrix-multiplication","text":"vector<vector<int>> matrixMultiply(const vector<vector<int>>& A, const vector<vector<int>>& B) { int n = A.size(); int m = A[0].size(); int p = B[0].size(); vector<vector<int>> C(n, vector<int>(p, 0)); for (int i = 0; i < n; i++) { for (int j = 0; j < p; j++) { for (int k = 0; k < m; k++) { C[i][j] += A[i][k] * B[k][j]; } } } return C; } Time Complexity: O(n\u00b3)","title":"Matrix Multiplication"},{"location":"algorithms/math/#matrix-exponentiation","text":"vector<vector<int>> matrixPow(vector<vector<int>> A, int power) { int n = A.size(); // Initialize result to identity matrix vector<vector<int>> result(n, vector<int>(n, 0)); for (int i = 0; i < n; i++) { result[i][i] = 1; } while (power > 0) { if (power & 1) { result = matrixMultiply(result, A); } A = matrixMultiply(A, A); power >>= 1; } return result; } Time Complexity: O(n\u00b3 log power)","title":"Matrix Exponentiation"},{"location":"algorithms/math/#geometric-algorithms","text":"","title":"Geometric Algorithms"},{"location":"algorithms/math/#distance-between-points","text":"double distance(double x1, double y1, double x2, double y2) { return sqrt(pow(x2 - x1, 2) + pow(y2 - y1, 2)); }","title":"Distance between Points"},{"location":"algorithms/math/#area-of-triangle","text":"// Using coordinates double triangleArea(double x1, double y1, double x2, double y2, double x3, double y3) { return 0.5 * abs(x1 * (y2 - y3) + x2 * (y3 - y1) + x3 * (y1 - y2)); } // Using sides (Heron's formula) double triangleArea(double a, double b, double c) { double s = (a + b + c) / 2; return sqrt(s * (s - a) * (s - b) * (s - c)); }","title":"Area of Triangle"},{"location":"algorithms/searching/","text":"Searching Algorithms This document covers various searching algorithms, their implementations, time complexities, and applications. Linear Search Simplest searching algorithm that checks each element in sequence. int linearSearch(vector<int>& arr, int target) { for (int i = 0; i < arr.size(); i++) { if (arr[i] == target) { return i; // Return index if found } } return -1; // Not found } Time Complexity: - Average: O(n) - Worst: O(n) - Best: O(1) (if element is at the first position) Space Complexity: O(1) Advantages: - Simple to implement - Works on unsorted arrays - Only option for linked lists when random access isn't available Disadvantages: - Inefficient for large datasets Binary Search Divide-and-conquer algorithm that works on sorted arrays. int binarySearch(vector<int>& arr, int target) { int left = 0; int right = arr.size() - 1; while (left <= right) { int mid = left + (right - left) / 2; // Avoid potential overflow if (arr[mid] == target) { return mid; // Found the target } else if (arr[mid] < target) { left = mid + 1; // Search in the right half } else { right = mid - 1; // Search in the left half } } return -1; // Target not found } Time Complexity: - Average: O(log n) - Worst: O(log n) - Best: O(1) (if element is at the middle position) Space Complexity: - Iterative: O(1) - Recursive: O(log n) due to call stack Advantages: - Very efficient for large datasets - Works well with arrays that support random access Disadvantages: - Requires sorted array - Not suitable for data structures that don't allow random access Recursive Binary Search int binarySearchRecursive(vector<int>& arr, int target, int left, int right) { if (left > right) { return -1; // Base case: target not found } int mid = left + (right - left) / 2; if (arr[mid] == target) { return mid; // Found the target } else if (arr[mid] < target) { return binarySearchRecursive(arr, target, mid + 1, right); // Search right half } else { return binarySearchRecursive(arr, target, left, mid - 1); // Search left half } } // Wrapper function int binarySearchRecursive(vector<int>& arr, int target) { return binarySearchRecursive(arr, target, 0, arr.size() - 1); } Finding Lower and Upper Bounds Often used when elements can be repeated. // Find the first occurrence of target int lowerBound(vector<int>& arr, int target) { int left = 0; int right = arr.size(); // One past the last element while (left < right) { int mid = left + (right - left) / 2; if (arr[mid] < target) { left = mid + 1; } else { right = mid; } } return (left < arr.size() && arr[left] == target) ? left : -1; } // Find the last occurrence of target int upperBound(vector<int>& arr, int target) { int left = 0; int right = arr.size(); // One past the last element while (left < right) { int mid = left + (right - left) / 2; if (arr[mid] <= target) { left = mid + 1; } else { right = mid; } } return (left > 0 && arr[left - 1] == target) ? left - 1 : -1; } Binary Search on Answer Used for optimization problems when we can check if a given value is feasible. // Example: Find the minimum capacity of ships to ship packages within D days int shipWithinDays(vector<int>& weights, int days) { int left = *max_element(weights.begin(), weights.end()); // Minimum possible capacity int right = accumulate(weights.begin(), weights.end(), 0); // Maximum possible capacity auto feasible = [&](int capacity) { int daysNeeded = 1; int currentLoad = 0; for (int weight : weights) { if (currentLoad + weight > capacity) { daysNeeded++; currentLoad = 0; } currentLoad += weight; } return daysNeeded <= days; }; while (left < right) { int mid = left + (right - left) / 2; if (feasible(mid)) { right = mid; // Try a smaller capacity } else { left = mid + 1; // Need a larger capacity } } return left; } Jump Search A middle ground between linear and binary search, especially useful for sorted arrays that are too large to fit in memory. int jumpSearch(vector<int>& arr, int target) { int n = arr.size(); int step = sqrt(n); // Optimal jump size // Find the block where the element might be present int prev = 0; while (arr[min(step, n) - 1] < target) { prev = step; step += sqrt(n); if (prev >= n) { return -1; // Not found } } // Linear search in the identified block while (arr[prev] < target) { prev++; if (prev == min(step, n)) { return -1; // Not found } } if (arr[prev] == target) { return prev; // Found } return -1; // Not found } Time Complexity: O(\u221an) Interpolation Search An improvement over binary search for uniformly distributed sorted arrays. int interpolationSearch(vector<int>& arr, int target) { int left = 0; int right = arr.size() - 1; while (left <= right && target >= arr[left] && target <= arr[right]) { // Formula for probing position int pos = left + ((double)(right - left) / (arr[right] - arr[left])) * (target - arr[left]); if (arr[pos] == target) { return pos; // Found } if (arr[pos] < target) { left = pos + 1; // Search in right half } else { right = pos - 1; // Search in left half } } return -1; // Not found } Time Complexity: - Average: O(log log n) for uniformly distributed data - Worst: O(n) when data is not uniformly distributed Exponential Search Useful for unbounded searches and better than binary search for bounded arrays when the element is near the beginning. int exponentialSearch(vector<int>& arr, int target) { int n = arr.size(); // If target is at first position if (arr[0] == target) { return 0; } // Find range for binary search int i = 1; while (i < n && arr[i] <= target) { i *= 2; } // Perform binary search on the range [i/2, min(i, n-1)] return binarySearchRecursive(arr, target, i / 2, min(i, n - 1)); } Time Complexity: O(log n) Fibonacci Search Uses Fibonacci numbers to divide the array, useful when binary search's uniform division is not optimal. int fibonacciSearch(vector<int>& arr, int target) { int n = arr.size(); // Initialize Fibonacci numbers int fibM2 = 0; // (m-2)'th Fibonacci number int fibM1 = 1; // (m-1)'th Fibonacci number int fibM = fibM1 + fibM2; // m'th Fibonacci number // Find smallest Fibonacci number >= n while (fibM < n) { fibM2 = fibM1; fibM1 = fibM; fibM = fibM1 + fibM2; } // Marks the eliminated range from front int offset = -1; // Search in the array while (fibM > 1) { // Check if fibM2 is a valid index int i = min(offset + fibM2, n - 1); if (arr[i] < target) { fibM = fibM1; fibM1 = fibM2; fibM2 = fibM - fibM1; offset = i; } else if (arr[i] > target) { fibM = fibM2; fibM1 = fibM1 - fibM2; fibM2 = fibM - fibM1; } else { return i; // Found } } // Check the last element if (fibM1 && arr[offset + 1] == target) { return offset + 1; } return -1; // Not found } Time Complexity: O(log n) Searching in 2D Arrays Row-wise and Column-wise Sorted Matrix pair<int, int> searchMatrix(vector<vector<int>>& matrix, int target) { int rows = matrix.size(); if (rows == 0) return {-1, -1}; int cols = matrix[0].size(); if (cols == 0) return {-1, -1}; // Start from top-right corner int row = 0; int col = cols - 1; while (row < rows && col >= 0) { if (matrix[row][col] == target) { return {row, col}; // Found } else if (matrix[row][col] > target) { col--; // Move left } else { row++; // Move down } } return {-1, -1}; // Not found } Time Complexity: O(rows + cols) Applications Database Systems : Indexing and retrieval operations Compiler Design : Symbol table lookups Information Retrieval : Searching for documents Machine Learning : k-nearest neighbors algorithm Geographic Information Systems : Spatial indexing Choosing the Right Search Algorithm Algorithm When to Use Linear Search Small datasets, unsorted arrays, linked lists Binary Search Large sorted arrays, log-time requirement Jump Search Large sorted arrays that don't fit in memory Interpolation Search Uniformly distributed sorted arrays Exponential Search Unbounded arrays, element near beginning Fibonacci Search When division points need to be biased Practice Problems Find first and last occurrence of an element in a sorted array Search in a rotated sorted array Find the peak element in a bitonic array Find the missing number in an array of 1 to n Search in a nearly sorted array Find the smallest letter greater than target","title":"Searching"},{"location":"algorithms/searching/#searching-algorithms","text":"This document covers various searching algorithms, their implementations, time complexities, and applications.","title":"Searching Algorithms"},{"location":"algorithms/searching/#linear-search","text":"Simplest searching algorithm that checks each element in sequence. int linearSearch(vector<int>& arr, int target) { for (int i = 0; i < arr.size(); i++) { if (arr[i] == target) { return i; // Return index if found } } return -1; // Not found } Time Complexity: - Average: O(n) - Worst: O(n) - Best: O(1) (if element is at the first position) Space Complexity: O(1) Advantages: - Simple to implement - Works on unsorted arrays - Only option for linked lists when random access isn't available Disadvantages: - Inefficient for large datasets","title":"Linear Search"},{"location":"algorithms/searching/#binary-search","text":"Divide-and-conquer algorithm that works on sorted arrays. int binarySearch(vector<int>& arr, int target) { int left = 0; int right = arr.size() - 1; while (left <= right) { int mid = left + (right - left) / 2; // Avoid potential overflow if (arr[mid] == target) { return mid; // Found the target } else if (arr[mid] < target) { left = mid + 1; // Search in the right half } else { right = mid - 1; // Search in the left half } } return -1; // Target not found } Time Complexity: - Average: O(log n) - Worst: O(log n) - Best: O(1) (if element is at the middle position) Space Complexity: - Iterative: O(1) - Recursive: O(log n) due to call stack Advantages: - Very efficient for large datasets - Works well with arrays that support random access Disadvantages: - Requires sorted array - Not suitable for data structures that don't allow random access","title":"Binary Search"},{"location":"algorithms/searching/#recursive-binary-search","text":"int binarySearchRecursive(vector<int>& arr, int target, int left, int right) { if (left > right) { return -1; // Base case: target not found } int mid = left + (right - left) / 2; if (arr[mid] == target) { return mid; // Found the target } else if (arr[mid] < target) { return binarySearchRecursive(arr, target, mid + 1, right); // Search right half } else { return binarySearchRecursive(arr, target, left, mid - 1); // Search left half } } // Wrapper function int binarySearchRecursive(vector<int>& arr, int target) { return binarySearchRecursive(arr, target, 0, arr.size() - 1); }","title":"Recursive Binary Search"},{"location":"algorithms/searching/#finding-lower-and-upper-bounds","text":"Often used when elements can be repeated. // Find the first occurrence of target int lowerBound(vector<int>& arr, int target) { int left = 0; int right = arr.size(); // One past the last element while (left < right) { int mid = left + (right - left) / 2; if (arr[mid] < target) { left = mid + 1; } else { right = mid; } } return (left < arr.size() && arr[left] == target) ? left : -1; } // Find the last occurrence of target int upperBound(vector<int>& arr, int target) { int left = 0; int right = arr.size(); // One past the last element while (left < right) { int mid = left + (right - left) / 2; if (arr[mid] <= target) { left = mid + 1; } else { right = mid; } } return (left > 0 && arr[left - 1] == target) ? left - 1 : -1; }","title":"Finding Lower and Upper Bounds"},{"location":"algorithms/searching/#binary-search-on-answer","text":"Used for optimization problems when we can check if a given value is feasible. // Example: Find the minimum capacity of ships to ship packages within D days int shipWithinDays(vector<int>& weights, int days) { int left = *max_element(weights.begin(), weights.end()); // Minimum possible capacity int right = accumulate(weights.begin(), weights.end(), 0); // Maximum possible capacity auto feasible = [&](int capacity) { int daysNeeded = 1; int currentLoad = 0; for (int weight : weights) { if (currentLoad + weight > capacity) { daysNeeded++; currentLoad = 0; } currentLoad += weight; } return daysNeeded <= days; }; while (left < right) { int mid = left + (right - left) / 2; if (feasible(mid)) { right = mid; // Try a smaller capacity } else { left = mid + 1; // Need a larger capacity } } return left; }","title":"Binary Search on Answer"},{"location":"algorithms/searching/#jump-search","text":"A middle ground between linear and binary search, especially useful for sorted arrays that are too large to fit in memory. int jumpSearch(vector<int>& arr, int target) { int n = arr.size(); int step = sqrt(n); // Optimal jump size // Find the block where the element might be present int prev = 0; while (arr[min(step, n) - 1] < target) { prev = step; step += sqrt(n); if (prev >= n) { return -1; // Not found } } // Linear search in the identified block while (arr[prev] < target) { prev++; if (prev == min(step, n)) { return -1; // Not found } } if (arr[prev] == target) { return prev; // Found } return -1; // Not found } Time Complexity: O(\u221an)","title":"Jump Search"},{"location":"algorithms/searching/#interpolation-search","text":"An improvement over binary search for uniformly distributed sorted arrays. int interpolationSearch(vector<int>& arr, int target) { int left = 0; int right = arr.size() - 1; while (left <= right && target >= arr[left] && target <= arr[right]) { // Formula for probing position int pos = left + ((double)(right - left) / (arr[right] - arr[left])) * (target - arr[left]); if (arr[pos] == target) { return pos; // Found } if (arr[pos] < target) { left = pos + 1; // Search in right half } else { right = pos - 1; // Search in left half } } return -1; // Not found } Time Complexity: - Average: O(log log n) for uniformly distributed data - Worst: O(n) when data is not uniformly distributed","title":"Interpolation Search"},{"location":"algorithms/searching/#exponential-search","text":"Useful for unbounded searches and better than binary search for bounded arrays when the element is near the beginning. int exponentialSearch(vector<int>& arr, int target) { int n = arr.size(); // If target is at first position if (arr[0] == target) { return 0; } // Find range for binary search int i = 1; while (i < n && arr[i] <= target) { i *= 2; } // Perform binary search on the range [i/2, min(i, n-1)] return binarySearchRecursive(arr, target, i / 2, min(i, n - 1)); } Time Complexity: O(log n)","title":"Exponential Search"},{"location":"algorithms/searching/#fibonacci-search","text":"Uses Fibonacci numbers to divide the array, useful when binary search's uniform division is not optimal. int fibonacciSearch(vector<int>& arr, int target) { int n = arr.size(); // Initialize Fibonacci numbers int fibM2 = 0; // (m-2)'th Fibonacci number int fibM1 = 1; // (m-1)'th Fibonacci number int fibM = fibM1 + fibM2; // m'th Fibonacci number // Find smallest Fibonacci number >= n while (fibM < n) { fibM2 = fibM1; fibM1 = fibM; fibM = fibM1 + fibM2; } // Marks the eliminated range from front int offset = -1; // Search in the array while (fibM > 1) { // Check if fibM2 is a valid index int i = min(offset + fibM2, n - 1); if (arr[i] < target) { fibM = fibM1; fibM1 = fibM2; fibM2 = fibM - fibM1; offset = i; } else if (arr[i] > target) { fibM = fibM2; fibM1 = fibM1 - fibM2; fibM2 = fibM - fibM1; } else { return i; // Found } } // Check the last element if (fibM1 && arr[offset + 1] == target) { return offset + 1; } return -1; // Not found } Time Complexity: O(log n)","title":"Fibonacci Search"},{"location":"algorithms/searching/#searching-in-2d-arrays","text":"","title":"Searching in 2D Arrays"},{"location":"algorithms/searching/#row-wise-and-column-wise-sorted-matrix","text":"pair<int, int> searchMatrix(vector<vector<int>>& matrix, int target) { int rows = matrix.size(); if (rows == 0) return {-1, -1}; int cols = matrix[0].size(); if (cols == 0) return {-1, -1}; // Start from top-right corner int row = 0; int col = cols - 1; while (row < rows && col >= 0) { if (matrix[row][col] == target) { return {row, col}; // Found } else if (matrix[row][col] > target) { col--; // Move left } else { row++; // Move down } } return {-1, -1}; // Not found } Time Complexity: O(rows + cols)","title":"Row-wise and Column-wise Sorted Matrix"},{"location":"algorithms/searching/#applications","text":"Database Systems : Indexing and retrieval operations Compiler Design : Symbol table lookups Information Retrieval : Searching for documents Machine Learning : k-nearest neighbors algorithm Geographic Information Systems : Spatial indexing","title":"Applications"},{"location":"algorithms/searching/#choosing-the-right-search-algorithm","text":"Algorithm When to Use Linear Search Small datasets, unsorted arrays, linked lists Binary Search Large sorted arrays, log-time requirement Jump Search Large sorted arrays that don't fit in memory Interpolation Search Uniformly distributed sorted arrays Exponential Search Unbounded arrays, element near beginning Fibonacci Search When division points need to be biased","title":"Choosing the Right Search Algorithm"},{"location":"algorithms/searching/#practice-problems","text":"Find first and last occurrence of an element in a sorted array Search in a rotated sorted array Find the peak element in a bitonic array Find the missing number in an array of 1 to n Search in a nearly sorted array Find the smallest letter greater than target","title":"Practice Problems"},{"location":"algorithms/sorting/","text":"Sorting Algorithms This document covers common sorting algorithms, their implementations, time and space complexities, and practical use cases. Bubble Sort A simple comparison-based algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they're in the wrong order. void bubbleSort(vector<int>& arr) { int n = arr.size(); bool swapped; for (int i = 0; i < n - 1; i++) { swapped = false; for (int j = 0; j < n - i - 1; j++) { if (arr[j] > arr[j + 1]) { swap(arr[j], arr[j + 1]); swapped = true; } } // If no swapping occurred in this pass, array is sorted if (!swapped) { break; } } } Time Complexity: - Best: O(n) when array is already sorted - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple to understand and implement - Works well for small datasets - Stable sort (doesn't change relative order of equal elements) Disadvantages: - Inefficient for large datasets - Poor performance compared to other algorithms Selection Sort Repeatedly selects the smallest (or largest) element from the unsorted portion and puts it at the beginning (or end). void selectionSort(vector<int>& arr) { int n = arr.size(); for (int i = 0; i < n - 1; i++) { int min_idx = i; for (int j = i + 1; j < n; j++) { if (arr[j] < arr[min_idx]) { min_idx = j; } } // Swap the found minimum element with the element at index i if (min_idx != i) { swap(arr[i], arr[min_idx]); } } } Time Complexity: - Best: O(n\u00b2) - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple implementation - Performs well on small datasets - Minimizes the number of swaps (O(n) swaps) Disadvantages: - Inefficient for large datasets - Not stable Insertion Sort Builds the sorted array one element at a time by repeatedly taking the next element and inserting it into the already-sorted part of the array. void insertionSort(vector<int>& arr) { int n = arr.size(); for (int i = 1; i < n; i++) { int key = arr[i]; int j = i - 1; // Move elements greater than key to one position ahead while (j >= 0 && arr[j] > key) { arr[j + 1] = arr[j]; j--; } arr[j + 1] = key; } } Time Complexity: - Best: O(n) when array is already sorted - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple implementation - Efficient for small datasets - Stable sort - Adaptive (efficient for partially sorted arrays) - Works well for arrays that are almost sorted - Online algorithm (can sort as data arrives) Disadvantages: - Inefficient for large datasets Merge Sort A divide-and-conquer algorithm that divides the input array into two halves, recursively sorts them, and then merges the sorted halves. void merge(vector<int>& arr, int left, int mid, int right) { int n1 = mid - left + 1; int n2 = right - mid; // Create temporary arrays vector<int> L(n1), R(n2); // Copy data to temporary arrays for (int i = 0; i < n1; i++) { L[i] = arr[left + i]; } for (int j = 0; j < n2; j++) { R[j] = arr[mid + 1 + j]; } // Merge the temporary arrays back into arr[left..right] int i = 0, j = 0, k = left; while (i < n1 && j < n2) { if (L[i] <= R[j]) { arr[k] = L[i]; i++; } else { arr[k] = R[j]; j++; } k++; } // Copy the remaining elements of L[], if any while (i < n1) { arr[k] = L[i]; i++; k++; } // Copy the remaining elements of R[], if any while (j < n2) { arr[k] = R[j]; j++; k++; } } void mergeSort(vector<int>& arr, int left, int right) { if (left < right) { int mid = left + (right - left) / 2; // Sort first and second halves mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); // Merge the sorted halves merge(arr, left, mid, right); } } // Wrapper function void mergeSort(vector<int>& arr) { mergeSort(arr, 0, arr.size() - 1); } Time Complexity: - Best: O(n log n) - Average: O(n log n) - Worst: O(n log n) Space Complexity: O(n) Advantages: - Guaranteed O(n log n) performance - Stable sort - Works well for linked lists - External sorting (when data doesn't fit in memory) Disadvantages: - Requires extra space - Slower for small datasets compared to insertion sort - Not in-place (although there are in-place variations) Quick Sort Another divide-and-conquer algorithm that selects a 'pivot' element and partitions the array around the pivot. int partition(vector<int>& arr, int low, int high) { int pivot = arr[high]; // Choose the rightmost element as pivot int i = low - 1; // Index of smaller element for (int j = low; j < high; j++) { // If current element is smaller than the pivot if (arr[j] < pivot) { i++; swap(arr[i], arr[j]); } } // Place pivot in its correct position swap(arr[i + 1], arr[high]); return i + 1; } void quickSort(vector<int>& arr, int low, int high) { if (low < high) { // Partition the array int pi = partition(arr, low, high); // Sort elements before and after partition quickSort(arr, low, pi - 1); quickSort(arr, pi + 1, high); } } // Wrapper function void quickSort(vector<int>& arr) { quickSort(arr, 0, arr.size() - 1); } Time Complexity: - Best: O(n log n) - Average: O(n log n) - Worst: O(n\u00b2) when array is already sorted and pivot is always the smallest/largest element Space Complexity: O(log n) for the recursive call stack Advantages: - Typically faster in practice than other O(n log n) algorithms - In-place sorting - Cache-friendly - Tail-recursive, which can be optimized Disadvantages: - Worst-case O(n\u00b2) performance - Not stable - Poor pivot selection can lead to inefficient sorting Randomized Quick Sort To avoid worst-case scenarios, we can choose a random pivot: int randomPartition(vector<int>& arr, int low, int high) { // Generate a random index between low and high int random = low + rand() % (high - low + 1); // Swap the random element with the last element swap(arr[random], arr[high]); // Now use the standard partition method return partition(arr, low, high); } void randomizedQuickSort(vector<int>& arr, int low, int high) { if (low < high) { int pi = randomPartition(arr, low, high); randomizedQuickSort(arr, low, pi - 1); randomizedQuickSort(arr, pi + 1, high); } }","title":"Sorting"},{"location":"algorithms/sorting/#sorting-algorithms","text":"This document covers common sorting algorithms, their implementations, time and space complexities, and practical use cases.","title":"Sorting Algorithms"},{"location":"algorithms/sorting/#bubble-sort","text":"A simple comparison-based algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they're in the wrong order. void bubbleSort(vector<int>& arr) { int n = arr.size(); bool swapped; for (int i = 0; i < n - 1; i++) { swapped = false; for (int j = 0; j < n - i - 1; j++) { if (arr[j] > arr[j + 1]) { swap(arr[j], arr[j + 1]); swapped = true; } } // If no swapping occurred in this pass, array is sorted if (!swapped) { break; } } } Time Complexity: - Best: O(n) when array is already sorted - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple to understand and implement - Works well for small datasets - Stable sort (doesn't change relative order of equal elements) Disadvantages: - Inefficient for large datasets - Poor performance compared to other algorithms","title":"Bubble Sort"},{"location":"algorithms/sorting/#selection-sort","text":"Repeatedly selects the smallest (or largest) element from the unsorted portion and puts it at the beginning (or end). void selectionSort(vector<int>& arr) { int n = arr.size(); for (int i = 0; i < n - 1; i++) { int min_idx = i; for (int j = i + 1; j < n; j++) { if (arr[j] < arr[min_idx]) { min_idx = j; } } // Swap the found minimum element with the element at index i if (min_idx != i) { swap(arr[i], arr[min_idx]); } } } Time Complexity: - Best: O(n\u00b2) - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple implementation - Performs well on small datasets - Minimizes the number of swaps (O(n) swaps) Disadvantages: - Inefficient for large datasets - Not stable","title":"Selection Sort"},{"location":"algorithms/sorting/#insertion-sort","text":"Builds the sorted array one element at a time by repeatedly taking the next element and inserting it into the already-sorted part of the array. void insertionSort(vector<int>& arr) { int n = arr.size(); for (int i = 1; i < n; i++) { int key = arr[i]; int j = i - 1; // Move elements greater than key to one position ahead while (j >= 0 && arr[j] > key) { arr[j + 1] = arr[j]; j--; } arr[j + 1] = key; } } Time Complexity: - Best: O(n) when array is already sorted - Average: O(n\u00b2) - Worst: O(n\u00b2) Space Complexity: O(1) Advantages: - Simple implementation - Efficient for small datasets - Stable sort - Adaptive (efficient for partially sorted arrays) - Works well for arrays that are almost sorted - Online algorithm (can sort as data arrives) Disadvantages: - Inefficient for large datasets","title":"Insertion Sort"},{"location":"algorithms/sorting/#merge-sort","text":"A divide-and-conquer algorithm that divides the input array into two halves, recursively sorts them, and then merges the sorted halves. void merge(vector<int>& arr, int left, int mid, int right) { int n1 = mid - left + 1; int n2 = right - mid; // Create temporary arrays vector<int> L(n1), R(n2); // Copy data to temporary arrays for (int i = 0; i < n1; i++) { L[i] = arr[left + i]; } for (int j = 0; j < n2; j++) { R[j] = arr[mid + 1 + j]; } // Merge the temporary arrays back into arr[left..right] int i = 0, j = 0, k = left; while (i < n1 && j < n2) { if (L[i] <= R[j]) { arr[k] = L[i]; i++; } else { arr[k] = R[j]; j++; } k++; } // Copy the remaining elements of L[], if any while (i < n1) { arr[k] = L[i]; i++; k++; } // Copy the remaining elements of R[], if any while (j < n2) { arr[k] = R[j]; j++; k++; } } void mergeSort(vector<int>& arr, int left, int right) { if (left < right) { int mid = left + (right - left) / 2; // Sort first and second halves mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); // Merge the sorted halves merge(arr, left, mid, right); } } // Wrapper function void mergeSort(vector<int>& arr) { mergeSort(arr, 0, arr.size() - 1); } Time Complexity: - Best: O(n log n) - Average: O(n log n) - Worst: O(n log n) Space Complexity: O(n) Advantages: - Guaranteed O(n log n) performance - Stable sort - Works well for linked lists - External sorting (when data doesn't fit in memory) Disadvantages: - Requires extra space - Slower for small datasets compared to insertion sort - Not in-place (although there are in-place variations)","title":"Merge Sort"},{"location":"algorithms/sorting/#quick-sort","text":"Another divide-and-conquer algorithm that selects a 'pivot' element and partitions the array around the pivot. int partition(vector<int>& arr, int low, int high) { int pivot = arr[high]; // Choose the rightmost element as pivot int i = low - 1; // Index of smaller element for (int j = low; j < high; j++) { // If current element is smaller than the pivot if (arr[j] < pivot) { i++; swap(arr[i], arr[j]); } } // Place pivot in its correct position swap(arr[i + 1], arr[high]); return i + 1; } void quickSort(vector<int>& arr, int low, int high) { if (low < high) { // Partition the array int pi = partition(arr, low, high); // Sort elements before and after partition quickSort(arr, low, pi - 1); quickSort(arr, pi + 1, high); } } // Wrapper function void quickSort(vector<int>& arr) { quickSort(arr, 0, arr.size() - 1); } Time Complexity: - Best: O(n log n) - Average: O(n log n) - Worst: O(n\u00b2) when array is already sorted and pivot is always the smallest/largest element Space Complexity: O(log n) for the recursive call stack Advantages: - Typically faster in practice than other O(n log n) algorithms - In-place sorting - Cache-friendly - Tail-recursive, which can be optimized Disadvantages: - Worst-case O(n\u00b2) performance - Not stable - Poor pivot selection can lead to inefficient sorting","title":"Quick Sort"},{"location":"algorithms/sorting/#randomized-quick-sort","text":"To avoid worst-case scenarios, we can choose a random pivot: int randomPartition(vector<int>& arr, int low, int high) { // Generate a random index between low and high int random = low + rand() % (high - low + 1); // Swap the random element with the last element swap(arr[random], arr[high]); // Now use the standard partition method return partition(arr, low, high); } void randomizedQuickSort(vector<int>& arr, int low, int high) { if (low < high) { int pi = randomPartition(arr, low, high); randomizedQuickSort(arr, low, pi - 1); randomizedQuickSort(arr, pi + 1, high); } }","title":"Randomized Quick Sort"},{"location":"algorithms/string/","text":"String Algorithms A collection of essential string algorithms and techniques commonly used in programming. String Matching Naive String Matching The simplest approach to find all occurrences of a pattern in a text. vector<int> naiveSearch(string text, string pattern) { vector<int> positions; int n = text.length(); int m = pattern.length(); for (int i = 0; i <= n - m; i++) { int j; for (j = 0; j < m; j++) { if (text[i + j] != pattern[j]) break; } if (j == m) // Pattern found positions.push_back(i); } return positions; } Time Complexity: O(n * m) where n is the text length and m is the pattern length KMP Algorithm An efficient string matching algorithm that uses preprocessing to avoid unnecessary comparisons. vector<int> kmpSearch(string text, string pattern) { int n = text.length(); int m = pattern.length(); vector<int> positions; // Preprocessing: building the LPS array vector<int> lps(m, 0); int len = 0, i = 1; while (i < m) { if (pattern[i] == pattern[len]) { len++; lps[i] = len; i++; } else { if (len != 0) { len = lps[len - 1]; } else { lps[i] = 0; i++; } } } // Searching i = 0; int j = 0; while (i < n) { if (pattern[j] == text[i]) { i++; j++; } if (j == m) { positions.push_back(i - j); j = lps[j - 1]; } else if (i < n && pattern[j] != text[i]) { if (j != 0) j = lps[j - 1]; else i++; } } return positions; } Time Complexity: O(n + m) Common String Operations Palindrome Check bool isPalindrome(string s) { int left = 0; int right = s.length() - 1; while (left < right) { if (s[left] != s[right]) return false; left++; right--; } return true; } String Reversal string reverseString(string s) { int left = 0; int right = s.length() - 1; while (left < right) { swap(s[left], s[right]); left++; right--; } return s; } Anagram Check bool isAnagram(string s1, string s2) { if (s1.length() != s2.length()) return false; vector<int> count(26, 0); for (int i = 0; i < s1.length(); i++) { count[s1[i] - 'a']++; count[s2[i] - 'a']--; } for (int c : count) { if (c != 0) return false; } return true; } String Dynamic Programming Longest Common Subsequence int longestCommonSubsequence(string s1, string s2) { int m = s1.length(); int n = s2.length(); vector<vector<int>> dp(m + 1, vector<int>(n + 1, 0)); for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (s1[i-1] == s2[j-1]) dp[i][j] = dp[i-1][j-1] + 1; else dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } } return dp[m][n]; } Edit Distance int editDistance(string s1, string s2) { int m = s1.length(); int n = s2.length(); vector<vector<int>> dp(m + 1, vector<int>(n + 1, 0)); // Base cases for (int i = 0; i <= m; i++) dp[i][0] = i; for (int j = 0; j <= n; j++) dp[0][j] = j; // Fill dp table for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (s1[i-1] == s2[j-1]) dp[i][j] = dp[i-1][j-1]; else dp[i][j] = 1 + min({dp[i-1][j], dp[i][j-1], dp[i-1][j-1]}); } } return dp[m][n]; } Basic Data Structures Trie (Prefix Tree) A tree-like data structure useful for searching words in a dictionary. class TrieNode { public: bool isEndOfWord; TrieNode* children[26]; // For lowercase English letters TrieNode() { isEndOfWord = false; for (int i = 0; i < 26; i++) children[i] = nullptr; } }; class Trie { private: TrieNode* root; public: Trie() { root = new TrieNode(); } void insert(string word) { TrieNode* current = root; for (char c : word) { int index = c - 'a'; if (!current->children[index]) current->children[index] = new TrieNode(); current = current->children[index]; } current->isEndOfWord = true; } bool search(string word) { TrieNode* current = root; for (char c : word) { int index = c - 'a'; if (!current->children[index]) return false; current = current->children[index]; } return current->isEndOfWord; } bool startsWith(string prefix) { TrieNode* current = root; for (char c : prefix) { int index = c - 'a'; if (!current->children[index]) return false; current = current->children[index]; } return true; } }; Common Problems Substring Search : Finding occurrences of a pattern in a text Palindrome Detection : Checking if a string reads the same backward as forward Anagram Detection : Checking if two strings contain the same characters in different order String Compression : Encoding strings to reduce their size String Tokenization : Breaking a string into tokens based on delimiters Wildcard Matching : Matching patterns containing wildcards like '*' and '?' Prefix/Suffix Analysis : Finding common prefixes or suffixes in a set of strings","title":"Strings"},{"location":"algorithms/string/#string-algorithms","text":"A collection of essential string algorithms and techniques commonly used in programming.","title":"String Algorithms"},{"location":"algorithms/string/#string-matching","text":"","title":"String Matching"},{"location":"algorithms/string/#naive-string-matching","text":"The simplest approach to find all occurrences of a pattern in a text. vector<int> naiveSearch(string text, string pattern) { vector<int> positions; int n = text.length(); int m = pattern.length(); for (int i = 0; i <= n - m; i++) { int j; for (j = 0; j < m; j++) { if (text[i + j] != pattern[j]) break; } if (j == m) // Pattern found positions.push_back(i); } return positions; } Time Complexity: O(n * m) where n is the text length and m is the pattern length","title":"Naive String Matching"},{"location":"algorithms/string/#kmp-algorithm","text":"An efficient string matching algorithm that uses preprocessing to avoid unnecessary comparisons. vector<int> kmpSearch(string text, string pattern) { int n = text.length(); int m = pattern.length(); vector<int> positions; // Preprocessing: building the LPS array vector<int> lps(m, 0); int len = 0, i = 1; while (i < m) { if (pattern[i] == pattern[len]) { len++; lps[i] = len; i++; } else { if (len != 0) { len = lps[len - 1]; } else { lps[i] = 0; i++; } } } // Searching i = 0; int j = 0; while (i < n) { if (pattern[j] == text[i]) { i++; j++; } if (j == m) { positions.push_back(i - j); j = lps[j - 1]; } else if (i < n && pattern[j] != text[i]) { if (j != 0) j = lps[j - 1]; else i++; } } return positions; } Time Complexity: O(n + m)","title":"KMP Algorithm"},{"location":"algorithms/string/#common-string-operations","text":"","title":"Common String Operations"},{"location":"algorithms/string/#palindrome-check","text":"bool isPalindrome(string s) { int left = 0; int right = s.length() - 1; while (left < right) { if (s[left] != s[right]) return false; left++; right--; } return true; }","title":"Palindrome Check"},{"location":"algorithms/string/#string-reversal","text":"string reverseString(string s) { int left = 0; int right = s.length() - 1; while (left < right) { swap(s[left], s[right]); left++; right--; } return s; }","title":"String Reversal"},{"location":"algorithms/string/#anagram-check","text":"bool isAnagram(string s1, string s2) { if (s1.length() != s2.length()) return false; vector<int> count(26, 0); for (int i = 0; i < s1.length(); i++) { count[s1[i] - 'a']++; count[s2[i] - 'a']--; } for (int c : count) { if (c != 0) return false; } return true; }","title":"Anagram Check"},{"location":"algorithms/string/#string-dynamic-programming","text":"","title":"String Dynamic Programming"},{"location":"algorithms/string/#longest-common-subsequence","text":"int longestCommonSubsequence(string s1, string s2) { int m = s1.length(); int n = s2.length(); vector<vector<int>> dp(m + 1, vector<int>(n + 1, 0)); for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (s1[i-1] == s2[j-1]) dp[i][j] = dp[i-1][j-1] + 1; else dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } } return dp[m][n]; }","title":"Longest Common Subsequence"},{"location":"algorithms/string/#edit-distance","text":"int editDistance(string s1, string s2) { int m = s1.length(); int n = s2.length(); vector<vector<int>> dp(m + 1, vector<int>(n + 1, 0)); // Base cases for (int i = 0; i <= m; i++) dp[i][0] = i; for (int j = 0; j <= n; j++) dp[0][j] = j; // Fill dp table for (int i = 1; i <= m; i++) { for (int j = 1; j <= n; j++) { if (s1[i-1] == s2[j-1]) dp[i][j] = dp[i-1][j-1]; else dp[i][j] = 1 + min({dp[i-1][j], dp[i][j-1], dp[i-1][j-1]}); } } return dp[m][n]; }","title":"Edit Distance"},{"location":"algorithms/string/#basic-data-structures","text":"","title":"Basic Data Structures"},{"location":"algorithms/string/#trie-prefix-tree","text":"A tree-like data structure useful for searching words in a dictionary. class TrieNode { public: bool isEndOfWord; TrieNode* children[26]; // For lowercase English letters TrieNode() { isEndOfWord = false; for (int i = 0; i < 26; i++) children[i] = nullptr; } }; class Trie { private: TrieNode* root; public: Trie() { root = new TrieNode(); } void insert(string word) { TrieNode* current = root; for (char c : word) { int index = c - 'a'; if (!current->children[index]) current->children[index] = new TrieNode(); current = current->children[index]; } current->isEndOfWord = true; } bool search(string word) { TrieNode* current = root; for (char c : word) { int index = c - 'a'; if (!current->children[index]) return false; current = current->children[index]; } return current->isEndOfWord; } bool startsWith(string prefix) { TrieNode* current = root; for (char c : prefix) { int index = c - 'a'; if (!current->children[index]) return false; current = current->children[index]; } return true; } };","title":"Trie (Prefix Tree)"},{"location":"algorithms/string/#common-problems","text":"Substring Search : Finding occurrences of a pattern in a text Palindrome Detection : Checking if a string reads the same backward as forward Anagram Detection : Checking if two strings contain the same characters in different order String Compression : Encoding strings to reduce their size String Tokenization : Breaking a string into tokens based on delimiters Wildcard Matching : Matching patterns containing wildcards like '*' and '?' Prefix/Suffix Analysis : Finding common prefixes or suffixes in a set of strings","title":"Common Problems"},{"location":"cpp/stl/","text":"C++ Standard Template Library (STL) The C++ STL is a powerful collection of template classes and functions providing common data structures and algorithms. Containers Sequence Containers vector Dynamic array with automatic resizing. #include <vector> vector<int> vec; // Empty vector vector<int> vec = {1, 2, 3, 4}; // Initialization with values vector<int> vec(10, 0); // Vector of size 10 with all values as 0 // Common operations vec.push_back(5); // Add element at the end vec.pop_back(); // Remove last element vec.size(); // Get size vec.empty(); // Check if empty vec.clear(); // Remove all elements vec.resize(5); // Resize vector vec[0]; // Access element (no bounds checking) vec.at(0); // Access element (with bounds checking) vec.front(); // Access first element vec.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase at end: O(1) amortized - Insert/Erase at arbitrary position: O(n) deque Double-ended queue supporting fast insertion and deletion at both ends. #include <deque> deque<int> dq; // Empty deque deque<int> dq = {1, 2, 3, 4}; // Initialization with values // Common operations dq.push_back(5); // Add element at the end dq.push_front(0); // Add element at the beginning dq.pop_back(); // Remove last element dq.pop_front(); // Remove first element dq.size(); // Get size dq.empty(); // Check if empty dq.clear(); // Remove all elements dq[0]; // Access element (no bounds checking) dq.at(0); // Access element (with bounds checking) dq.front(); // Access first element dq.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase at beginning/end: O(1) amortized - Insert/Erase at arbitrary position: O(n) list Doubly-linked list. #include <list> list<int> lst; // Empty list list<int> lst = {1, 2, 3, 4}; // Initialization with values // Common operations lst.push_back(5); // Add element at the end lst.push_front(0); // Add element at the beginning lst.pop_back(); // Remove last element lst.pop_front(); // Remove first element lst.size(); // Get size lst.empty(); // Check if empty lst.clear(); // Remove all elements auto it = lst.begin(); // Iterator to first element lst.insert(it, 10); // Insert 10 before position of iterator lst.erase(it); // Erase element at iterator lst.front(); // Access first element lst.back(); // Access last element lst.sort(); // Sort the list lst.reverse(); // Reverse the list lst.merge(list2); // Merge two sorted lists lst.splice(it, list2); // Insert list2 at position it Time Complexity: - Access: O(n) - Insert/Erase with known position: O(1) - Search: O(n) forward_list Singly-linked list. #include <forward_list> forward_list<int> fl; // Empty forward_list forward_list<int> fl = {1, 2, 3};// Initialization with values // Common operations fl.push_front(0); // Add element at the beginning fl.pop_front(); // Remove first element fl.empty(); // Check if empty fl.clear(); // Remove all elements auto it = fl.begin(); // Iterator to first element auto it_before = fl.before_begin(); // Iterator before first element fl.insert_after(it, 10); // Insert 10 after position of iterator fl.erase_after(it); // Erase element after iterator fl.front(); // Access first element fl.sort(); // Sort the forward_list fl.reverse(); // Reverse the forward_list Time Complexity: - Access: O(n) - Insert/Erase with known position: O(1) - Search: O(n) array Fixed-size array. #include <array> array<int, 5> arr; // Uninitialized array of size 5 array<int, 5> arr = {1, 2, 3, 4, 5}; // Initialization with values // Common operations arr.size(); // Get size arr.empty(); // Check if empty arr.fill(0); // Fill with 0s arr[0]; // Access element (no bounds checking) arr.at(0); // Access element (with bounds checking) arr.front(); // Access first element arr.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase: Not supported (fixed size) Associative Containers set Collection of unique keys, sorted by keys. #include <set> set<int> s; // Empty set set<int> s = {1, 2, 3, 4}; // Initialization with values // Common operations s.insert(5); // Insert element s.erase(3); // Remove element with value 3 s.size(); // Get size s.empty(); // Check if empty s.clear(); // Remove all elements s.find(2); // Find element with value 2 s.count(2); // Count elements with value 2 (0 or 1) s.lower_bound(3); // Iterator to first element >= 3 s.upper_bound(3); // Iterator to first element > 3 Time Complexity: - Insert/Erase/Find: O(log n) multiset Collection of keys, sorted by keys (allows duplicates). #include <set> multiset<int> ms; // Empty multiset multiset<int> ms = {1, 2, 2, 3}; // Initialization with values // Common operations (similar to set) ms.insert(5); // Insert element ms.erase(3); // Remove all elements with value 3 auto it = ms.find(2); // Find first element with value 2 ms.erase(it); // Remove specific occurrence of 2 ms.count(2); // Count elements with value 2 Time Complexity: - Insert/Erase/Find: O(log n) map Collection of key-value pairs, sorted by keys, keys are unique. #include <map> map<string, int> mp; // Empty map {% raw %} map<string, int> mp = {{\"apple\", 5}, {\"banana\", 3}}; // Initialization with values {% endraw %} // Common operations mp[\"orange\"] = 2; // Insert or update key-value pair mp.insert({\"pear\", 4}); // Insert key-value pair mp.insert(make_pair(\"grape\", 6));// Another way to insert mp.erase(\"apple\"); // Remove element with key \"apple\" mp.size(); // Get size mp.empty(); // Check if empty mp.clear(); // Remove all elements mp.find(\"banana\"); // Find element with key \"banana\" mp.count(\"banana\"); // Count elements with key \"banana\" (0 or 1) Time Complexity: - Insert/Erase/Find: O(log n) multimap Collection of key-value pairs, sorted by keys (allows duplicate keys). #include <map> multimap<string, int> mm; // Empty multimap mm.insert({\"apple\", 5}); // Insert key-value pair mm.insert({\"apple\", 3}); // Insert another with same key Time Complexity: - Insert/Erase/Find: O(log n) Unordered Associative Containers unordered_set Collection of unique keys, hashed by keys. #include <unordered_set> unordered_set<int> us; // Empty unordered_set unordered_set<int> us = {1, 2, 3, 4}; // Initialization with values // Common operations (similar to set, but unordered) us.insert(5); // Insert element us.erase(3); // Remove element with value 3 us.find(2); // Find element with value 2 us.count(2); // Count elements with value 2 (0 or 1) Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case unordered_multiset Collection of keys, hashed by keys (allows duplicates). #include <unordered_set> unordered_multiset<int> ums; // Empty unordered_multiset ums.insert(2); // Insert element ums.insert(2); // Insert duplicate Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case unordered_map Collection of key-value pairs, hashed by keys, keys are unique. #include <unordered_map> unordered_map<string, int> um; // Empty unordered_map um[\"apple\"] = 5; // Insert or update key-value pair um.insert({\"banana\", 3}); // Insert key-value pair Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case unordered_multimap Collection of key-value pairs, hashed by keys (allows duplicate keys). #include <unordered_map> unordered_multimap<string, int> umm; // Empty unordered_multimap umm.insert({\"apple\", 5}); // Insert key-value pair umm.insert({\"apple\", 3}); // Insert another with same key Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case Container Adaptors stack LIFO (Last In, First Out) data structure. #include <stack> stack<int> stk; // Empty stack stk.push(1); // Add element to top stk.push(2); // Add element to top int top = stk.top(); // Access top element (2) stk.pop(); // Remove top element stk.size(); // Get size stk.empty(); // Check if empty Time Complexity: - Push/Pop/Top: O(1) queue FIFO (First In, First Out) data structure. #include <queue> queue<int> q; // Empty queue q.push(1); // Add element to back q.push(2); // Add element to back int front = q.front(); // Access front element (1) int back = q.back(); // Access back element (2) q.pop(); // Remove front element q.size(); // Get size q.empty(); // Check if empty Time Complexity: - Push/Pop/Front/Back: O(1) priority_queue Provides constant time lookup of the largest (by default) element. #include <queue> // Max heap (default) priority_queue<int> pq; // Empty priority queue pq.push(3); // Add element pq.push(5); // Add element pq.push(1); // Add element int top = pq.top(); // Access largest element (5) pq.pop(); // Remove largest element pq.size(); // Get size pq.empty(); // Check if empty // Min heap priority_queue<int, vector<int>, greater<int>> min_pq; min_pq.push(3); // Add element min_pq.push(5); // Add element min_pq.push(1); // Add element int min_top = min_pq.top(); // Access smallest element (1) Time Complexity: - Push/Pop: O(log n) - Top: O(1) Algorithms STL provides various algorithms for common operations on containers. #include <algorithm> vector<int> v = {5, 2, 8, 1, 3}; // Sorting sort(v.begin(), v.end()); // Sort in ascending order sort(v.begin(), v.end(), greater<int>()); // Sort in descending order // Binary search (on sorted range) binary_search(v.begin(), v.end(), 3); // Returns true if 3 is in vector lower_bound(v.begin(), v.end(), 3); // Iterator to first element >= 3 upper_bound(v.begin(), v.end(), 3); // Iterator to first element > 3 // Min/Max *min_element(v.begin(), v.end()); // Smallest element *max_element(v.begin(), v.end()); // Largest element // Finding find(v.begin(), v.end(), 3); // Iterator to first occurrence of 3 count(v.begin(), v.end(), 3); // Count occurrences of 3 // Manipulation reverse(v.begin(), v.end()); // Reverse the vector rotate(v.begin(), v.begin() + 2, v.end()); // Rotate vector left by 2 positions random_shuffle(v.begin(), v.end()); // Randomly shuffle elements // Heap operations make_heap(v.begin(), v.end()); // Convert range to a heap push_heap(v.begin(), v.end()); // Add element to heap pop_heap(v.begin(), v.end()); // Move largest element to end and reconstitute heap // Numeric #include <numeric> accumulate(v.begin(), v.end(), 0); // Sum of elements (starting with 0) partial_sum(v.begin(), v.end(), result.begin()); // Partial sums Iterators Iterators are used to access and traverse container elements. vector<int> v = {1, 2, 3, 4, 5}; // Types of iterators auto it = v.begin(); // Regular iterator auto rit = v.rbegin(); // Reverse iterator auto cit = v.cbegin(); // Constant iterator auto crit = v.crbegin(); // Constant reverse iterator // Iterator operations it++; // Move to next element it--; // Move to previous element it += 2; // Move forward by 2 (random access) *it; // Access element it = v.end(); // Iterator to one past the last element Utility Classes pair Holds two values of possibly different types. #include <utility> pair<string, int> p(\"apple\", 5); // Create pair auto p = make_pair(\"apple\", 5); // Alternative creation string first = p.first; // Access first element int second = p.second; // Access second element tuple Holds a fixed-size collection of elements of different types. #include <tuple> tuple<string, int, double> t(\"apple\", 5, 3.14); // Create tuple auto t = make_tuple(\"apple\", 5, 3.14); // Alternative creation string first = get<0>(t); // Access first element int second = get<1>(t); // Access second element double third = get<2>(t); // Access third element Best Practices Use the Right Container : Choose based on your access patterns and required operations. Avoid Premature Optimization : Start with a straightforward solution, then optimize if needed. Range-based for Loop : Prefer range-based for loops for cleaner code. cpp for (const auto& elem : container) { // Use elem } Use auto for Iterator Types : Makes code more readable and maintainable. Leverage STL Algorithms : They're well-tested and often more efficient than manual implementations. Pass by Reference : For large containers, pass by reference to avoid copying. Reserve Vector Capacity : If you know the size in advance, use vector::reserve() to avoid reallocations. Use emplace_back() Instead of push_back() : For objects that require construction, emplace_back() constructs in-place.","title":"STL"},{"location":"cpp/stl/#c-standard-template-library-stl","text":"The C++ STL is a powerful collection of template classes and functions providing common data structures and algorithms.","title":"C++ Standard Template Library (STL)"},{"location":"cpp/stl/#containers","text":"","title":"Containers"},{"location":"cpp/stl/#sequence-containers","text":"","title":"Sequence Containers"},{"location":"cpp/stl/#vector","text":"Dynamic array with automatic resizing. #include <vector> vector<int> vec; // Empty vector vector<int> vec = {1, 2, 3, 4}; // Initialization with values vector<int> vec(10, 0); // Vector of size 10 with all values as 0 // Common operations vec.push_back(5); // Add element at the end vec.pop_back(); // Remove last element vec.size(); // Get size vec.empty(); // Check if empty vec.clear(); // Remove all elements vec.resize(5); // Resize vector vec[0]; // Access element (no bounds checking) vec.at(0); // Access element (with bounds checking) vec.front(); // Access first element vec.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase at end: O(1) amortized - Insert/Erase at arbitrary position: O(n)","title":"vector"},{"location":"cpp/stl/#deque","text":"Double-ended queue supporting fast insertion and deletion at both ends. #include <deque> deque<int> dq; // Empty deque deque<int> dq = {1, 2, 3, 4}; // Initialization with values // Common operations dq.push_back(5); // Add element at the end dq.push_front(0); // Add element at the beginning dq.pop_back(); // Remove last element dq.pop_front(); // Remove first element dq.size(); // Get size dq.empty(); // Check if empty dq.clear(); // Remove all elements dq[0]; // Access element (no bounds checking) dq.at(0); // Access element (with bounds checking) dq.front(); // Access first element dq.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase at beginning/end: O(1) amortized - Insert/Erase at arbitrary position: O(n)","title":"deque"},{"location":"cpp/stl/#list","text":"Doubly-linked list. #include <list> list<int> lst; // Empty list list<int> lst = {1, 2, 3, 4}; // Initialization with values // Common operations lst.push_back(5); // Add element at the end lst.push_front(0); // Add element at the beginning lst.pop_back(); // Remove last element lst.pop_front(); // Remove first element lst.size(); // Get size lst.empty(); // Check if empty lst.clear(); // Remove all elements auto it = lst.begin(); // Iterator to first element lst.insert(it, 10); // Insert 10 before position of iterator lst.erase(it); // Erase element at iterator lst.front(); // Access first element lst.back(); // Access last element lst.sort(); // Sort the list lst.reverse(); // Reverse the list lst.merge(list2); // Merge two sorted lists lst.splice(it, list2); // Insert list2 at position it Time Complexity: - Access: O(n) - Insert/Erase with known position: O(1) - Search: O(n)","title":"list"},{"location":"cpp/stl/#forward_list","text":"Singly-linked list. #include <forward_list> forward_list<int> fl; // Empty forward_list forward_list<int> fl = {1, 2, 3};// Initialization with values // Common operations fl.push_front(0); // Add element at the beginning fl.pop_front(); // Remove first element fl.empty(); // Check if empty fl.clear(); // Remove all elements auto it = fl.begin(); // Iterator to first element auto it_before = fl.before_begin(); // Iterator before first element fl.insert_after(it, 10); // Insert 10 after position of iterator fl.erase_after(it); // Erase element after iterator fl.front(); // Access first element fl.sort(); // Sort the forward_list fl.reverse(); // Reverse the forward_list Time Complexity: - Access: O(n) - Insert/Erase with known position: O(1) - Search: O(n)","title":"forward_list"},{"location":"cpp/stl/#array","text":"Fixed-size array. #include <array> array<int, 5> arr; // Uninitialized array of size 5 array<int, 5> arr = {1, 2, 3, 4, 5}; // Initialization with values // Common operations arr.size(); // Get size arr.empty(); // Check if empty arr.fill(0); // Fill with 0s arr[0]; // Access element (no bounds checking) arr.at(0); // Access element (with bounds checking) arr.front(); // Access first element arr.back(); // Access last element Time Complexity: - Access: O(1) - Insert/Erase: Not supported (fixed size)","title":"array"},{"location":"cpp/stl/#associative-containers","text":"","title":"Associative Containers"},{"location":"cpp/stl/#set","text":"Collection of unique keys, sorted by keys. #include <set> set<int> s; // Empty set set<int> s = {1, 2, 3, 4}; // Initialization with values // Common operations s.insert(5); // Insert element s.erase(3); // Remove element with value 3 s.size(); // Get size s.empty(); // Check if empty s.clear(); // Remove all elements s.find(2); // Find element with value 2 s.count(2); // Count elements with value 2 (0 or 1) s.lower_bound(3); // Iterator to first element >= 3 s.upper_bound(3); // Iterator to first element > 3 Time Complexity: - Insert/Erase/Find: O(log n)","title":"set"},{"location":"cpp/stl/#multiset","text":"Collection of keys, sorted by keys (allows duplicates). #include <set> multiset<int> ms; // Empty multiset multiset<int> ms = {1, 2, 2, 3}; // Initialization with values // Common operations (similar to set) ms.insert(5); // Insert element ms.erase(3); // Remove all elements with value 3 auto it = ms.find(2); // Find first element with value 2 ms.erase(it); // Remove specific occurrence of 2 ms.count(2); // Count elements with value 2 Time Complexity: - Insert/Erase/Find: O(log n)","title":"multiset"},{"location":"cpp/stl/#map","text":"Collection of key-value pairs, sorted by keys, keys are unique. #include <map> map<string, int> mp; // Empty map {% raw %} map<string, int> mp = {{\"apple\", 5}, {\"banana\", 3}}; // Initialization with values {% endraw %} // Common operations mp[\"orange\"] = 2; // Insert or update key-value pair mp.insert({\"pear\", 4}); // Insert key-value pair mp.insert(make_pair(\"grape\", 6));// Another way to insert mp.erase(\"apple\"); // Remove element with key \"apple\" mp.size(); // Get size mp.empty(); // Check if empty mp.clear(); // Remove all elements mp.find(\"banana\"); // Find element with key \"banana\" mp.count(\"banana\"); // Count elements with key \"banana\" (0 or 1) Time Complexity: - Insert/Erase/Find: O(log n)","title":"map"},{"location":"cpp/stl/#multimap","text":"Collection of key-value pairs, sorted by keys (allows duplicate keys). #include <map> multimap<string, int> mm; // Empty multimap mm.insert({\"apple\", 5}); // Insert key-value pair mm.insert({\"apple\", 3}); // Insert another with same key Time Complexity: - Insert/Erase/Find: O(log n)","title":"multimap"},{"location":"cpp/stl/#unordered-associative-containers","text":"","title":"Unordered Associative Containers"},{"location":"cpp/stl/#unordered_set","text":"Collection of unique keys, hashed by keys. #include <unordered_set> unordered_set<int> us; // Empty unordered_set unordered_set<int> us = {1, 2, 3, 4}; // Initialization with values // Common operations (similar to set, but unordered) us.insert(5); // Insert element us.erase(3); // Remove element with value 3 us.find(2); // Find element with value 2 us.count(2); // Count elements with value 2 (0 or 1) Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case","title":"unordered_set"},{"location":"cpp/stl/#unordered_multiset","text":"Collection of keys, hashed by keys (allows duplicates). #include <unordered_set> unordered_multiset<int> ums; // Empty unordered_multiset ums.insert(2); // Insert element ums.insert(2); // Insert duplicate Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case","title":"unordered_multiset"},{"location":"cpp/stl/#unordered_map","text":"Collection of key-value pairs, hashed by keys, keys are unique. #include <unordered_map> unordered_map<string, int> um; // Empty unordered_map um[\"apple\"] = 5; // Insert or update key-value pair um.insert({\"banana\", 3}); // Insert key-value pair Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case","title":"unordered_map"},{"location":"cpp/stl/#unordered_multimap","text":"Collection of key-value pairs, hashed by keys (allows duplicate keys). #include <unordered_map> unordered_multimap<string, int> umm; // Empty unordered_multimap umm.insert({\"apple\", 5}); // Insert key-value pair umm.insert({\"apple\", 3}); // Insert another with same key Time Complexity: - Insert/Erase/Find: O(1) average, O(n) worst case","title":"unordered_multimap"},{"location":"cpp/stl/#container-adaptors","text":"","title":"Container Adaptors"},{"location":"cpp/stl/#stack","text":"LIFO (Last In, First Out) data structure. #include <stack> stack<int> stk; // Empty stack stk.push(1); // Add element to top stk.push(2); // Add element to top int top = stk.top(); // Access top element (2) stk.pop(); // Remove top element stk.size(); // Get size stk.empty(); // Check if empty Time Complexity: - Push/Pop/Top: O(1)","title":"stack"},{"location":"cpp/stl/#queue","text":"FIFO (First In, First Out) data structure. #include <queue> queue<int> q; // Empty queue q.push(1); // Add element to back q.push(2); // Add element to back int front = q.front(); // Access front element (1) int back = q.back(); // Access back element (2) q.pop(); // Remove front element q.size(); // Get size q.empty(); // Check if empty Time Complexity: - Push/Pop/Front/Back: O(1)","title":"queue"},{"location":"cpp/stl/#priority_queue","text":"Provides constant time lookup of the largest (by default) element. #include <queue> // Max heap (default) priority_queue<int> pq; // Empty priority queue pq.push(3); // Add element pq.push(5); // Add element pq.push(1); // Add element int top = pq.top(); // Access largest element (5) pq.pop(); // Remove largest element pq.size(); // Get size pq.empty(); // Check if empty // Min heap priority_queue<int, vector<int>, greater<int>> min_pq; min_pq.push(3); // Add element min_pq.push(5); // Add element min_pq.push(1); // Add element int min_top = min_pq.top(); // Access smallest element (1) Time Complexity: - Push/Pop: O(log n) - Top: O(1)","title":"priority_queue"},{"location":"cpp/stl/#algorithms","text":"STL provides various algorithms for common operations on containers. #include <algorithm> vector<int> v = {5, 2, 8, 1, 3}; // Sorting sort(v.begin(), v.end()); // Sort in ascending order sort(v.begin(), v.end(), greater<int>()); // Sort in descending order // Binary search (on sorted range) binary_search(v.begin(), v.end(), 3); // Returns true if 3 is in vector lower_bound(v.begin(), v.end(), 3); // Iterator to first element >= 3 upper_bound(v.begin(), v.end(), 3); // Iterator to first element > 3 // Min/Max *min_element(v.begin(), v.end()); // Smallest element *max_element(v.begin(), v.end()); // Largest element // Finding find(v.begin(), v.end(), 3); // Iterator to first occurrence of 3 count(v.begin(), v.end(), 3); // Count occurrences of 3 // Manipulation reverse(v.begin(), v.end()); // Reverse the vector rotate(v.begin(), v.begin() + 2, v.end()); // Rotate vector left by 2 positions random_shuffle(v.begin(), v.end()); // Randomly shuffle elements // Heap operations make_heap(v.begin(), v.end()); // Convert range to a heap push_heap(v.begin(), v.end()); // Add element to heap pop_heap(v.begin(), v.end()); // Move largest element to end and reconstitute heap // Numeric #include <numeric> accumulate(v.begin(), v.end(), 0); // Sum of elements (starting with 0) partial_sum(v.begin(), v.end(), result.begin()); // Partial sums","title":"Algorithms"},{"location":"cpp/stl/#iterators","text":"Iterators are used to access and traverse container elements. vector<int> v = {1, 2, 3, 4, 5}; // Types of iterators auto it = v.begin(); // Regular iterator auto rit = v.rbegin(); // Reverse iterator auto cit = v.cbegin(); // Constant iterator auto crit = v.crbegin(); // Constant reverse iterator // Iterator operations it++; // Move to next element it--; // Move to previous element it += 2; // Move forward by 2 (random access) *it; // Access element it = v.end(); // Iterator to one past the last element","title":"Iterators"},{"location":"cpp/stl/#utility-classes","text":"","title":"Utility Classes"},{"location":"cpp/stl/#pair","text":"Holds two values of possibly different types. #include <utility> pair<string, int> p(\"apple\", 5); // Create pair auto p = make_pair(\"apple\", 5); // Alternative creation string first = p.first; // Access first element int second = p.second; // Access second element","title":"pair"},{"location":"cpp/stl/#tuple","text":"Holds a fixed-size collection of elements of different types. #include <tuple> tuple<string, int, double> t(\"apple\", 5, 3.14); // Create tuple auto t = make_tuple(\"apple\", 5, 3.14); // Alternative creation string first = get<0>(t); // Access first element int second = get<1>(t); // Access second element double third = get<2>(t); // Access third element","title":"tuple"},{"location":"cpp/stl/#best-practices","text":"Use the Right Container : Choose based on your access patterns and required operations. Avoid Premature Optimization : Start with a straightforward solution, then optimize if needed. Range-based for Loop : Prefer range-based for loops for cleaner code. cpp for (const auto& elem : container) { // Use elem } Use auto for Iterator Types : Makes code more readable and maintainable. Leverage STL Algorithms : They're well-tested and often more efficient than manual implementations. Pass by Reference : For large containers, pass by reference to avoid copying. Reserve Vector Capacity : If you know the size in advance, use vector::reserve() to avoid reallocations. Use emplace_back() Instead of push_back() : For objects that require construction, emplace_back() constructs in-place.","title":"Best Practices"},{"location":"system-design/ad-click-aggregator/","text":"","title":"Ad Click Aggregator"},{"location":"system-design/dropbox/","text":"","title":"Dropbox"},{"location":"system-design/live-comments/","text":"","title":"Live Comments"},{"location":"system-design/ticketmaster/","text":"","title":"Ticketmaster"},{"location":"system-design/tinder/","text":"Design Tinder Capacity Estimation Assumptions - Total Users: 100 million - DAU (Daily Active Users): 20 million - User activity: 10 swipes per user per day - User profile & preference size: 1 KB - Swipe data size: 100 bytes Storage Calculation - User profile & preferences: 100 million users * 1 KB = 100 GB - Daily swipes (30 days): 20 million users * 10 swipes/day * 30 days = 600 GB Bandwidth Calculation - Incoming Bandwidth (Swipes) = 20 million users * 10 swipes/day * 100 bytes / 10^5 seconds = 200 KB/s - Outgoing Bandwidth (1 profile viewed per swipe) = 20 million users * 10 swipes/day * 1 KB / 10^4 seconds = 2 MB/s QPS Calculation - Swipe QPS (Write operations) = 200 million swipes / day / 10^5 seconds - Profile View QPS (Read operations) =","title":"Tinder"},{"location":"system-design/tinder/#design-tinder","text":"","title":"Design Tinder"},{"location":"system-design/tinder/#capacity-estimation","text":"Assumptions - Total Users: 100 million - DAU (Daily Active Users): 20 million - User activity: 10 swipes per user per day - User profile & preference size: 1 KB - Swipe data size: 100 bytes Storage Calculation - User profile & preferences: 100 million users * 1 KB = 100 GB - Daily swipes (30 days): 20 million users * 10 swipes/day * 30 days = 600 GB Bandwidth Calculation - Incoming Bandwidth (Swipes) = 20 million users * 10 swipes/day * 100 bytes / 10^5 seconds = 200 KB/s - Outgoing Bandwidth (1 profile viewed per swipe) = 20 million users * 10 swipes/day * 1 KB / 10^4 seconds = 2 MB/s QPS Calculation - Swipe QPS (Write operations) = 200 million swipes / day / 10^5 seconds - Profile View QPS (Read operations) =","title":"Capacity Estimation"},{"location":"system-design/uber/","text":"","title":"Uber"},{"location":"system-design/whatsapp/","text":"","title":"Whatsapp"},{"location":"system-design/youtube-top-k/","text":"","title":"YouTube Top K"},{"location":"system-design/youtube/","text":"Design YouTube Capacity Estimation Assumptions - MAU (Monthly Active Users): 2 billion - DAU (Daily Active Users): 50% of MAU = 1 billion - Average video size: 50 MB - Video consumption per DAU: 5 videos - View to Upload ratio: 200 : 1 Video Views & Uploads per Day - Daily Video Views = 1 billion DAU * 5 videos = 5 billion views/day - Daily Video Uploads = 5 billion views/day / 200 = 25 million uploads/day Video Storage Calculation - Daily Storage = 25 million uploads/day * 50 MB = 1250 TB/day - With 3x encoding overhead = 3750 TB/day = 3.75 PB/day Bandwidth Calculation - Views Bandwidth = 5 billion views/day * 50 MB / 10^4 seconds = 5 * 10^9 * 50 * 10^6 / 10^4 = 25 TB/s - Upload Bandwidth = 25 TB / 200 / s = 125 GB/s QPS - Video Views per Second = 5 billion / 10^4 seconds = 500,000 QPS - Video Uploads per Second = 500,000 QPS / 200 = 2500 QPS Metadata Storage Calculation - Metadata Size = 1 KB per video & 0.5 KB per user - Storage time = 5 years = 5 * 400 days = 2000 days - 1 million new users/day (Assumption) - Video metadata storage = 2000 days * 25 million uploads/day * 1 KB = 50 TB - User metadata storage = 2000 days * 1 million new users/day * 0.5 KB = 1 TB","title":"YouTube"},{"location":"system-design/youtube/#design-youtube","text":"","title":"Design YouTube"},{"location":"system-design/youtube/#capacity-estimation","text":"Assumptions - MAU (Monthly Active Users): 2 billion - DAU (Daily Active Users): 50% of MAU = 1 billion - Average video size: 50 MB - Video consumption per DAU: 5 videos - View to Upload ratio: 200 : 1 Video Views & Uploads per Day - Daily Video Views = 1 billion DAU * 5 videos = 5 billion views/day - Daily Video Uploads = 5 billion views/day / 200 = 25 million uploads/day Video Storage Calculation - Daily Storage = 25 million uploads/day * 50 MB = 1250 TB/day - With 3x encoding overhead = 3750 TB/day = 3.75 PB/day Bandwidth Calculation - Views Bandwidth = 5 billion views/day * 50 MB / 10^4 seconds = 5 * 10^9 * 50 * 10^6 / 10^4 = 25 TB/s - Upload Bandwidth = 25 TB / 200 / s = 125 GB/s QPS - Video Views per Second = 5 billion / 10^4 seconds = 500,000 QPS - Video Uploads per Second = 500,000 QPS / 200 = 2500 QPS Metadata Storage Calculation - Metadata Size = 1 KB per video & 0.5 KB per user - Storage time = 5 years = 5 * 400 days = 2000 days - 1 million new users/day (Assumption) - Video metadata storage = 2000 days * 25 million uploads/day * 1 KB = 50 TB - User metadata storage = 2000 days * 1 million new users/day * 0.5 KB = 1 TB","title":"Capacity Estimation"}]}